{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from transformers import Wav2Vec2Processor,Wav2Vec2FeatureExtractor,AutoModel\n",
    "from tensorboardX import SummaryWriter\n",
    "from pt_utils import load_data, prepare_data, reshaping_data_for_model, unsplit_data_ogsize\n",
    "from pt_dataset import BreathingDataset\n",
    "import scipy.stats\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def prepare_test_datasets(path_to_test_data, path_to_test_labels, window_size=30, step_size=6, batch_size=10, processor=None):\n",
    "    \"\"\"\n",
    "    Load and prepare test datasets, saving them for later use\n",
    "    \"\"\"\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare test data\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_test_data, path_to_test_labels, 'test')\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(\n",
    "        test_data, test_labels, test_dict, frame_rate, \n",
    "        length_sequence * 16000, step_sequence * 16000\n",
    "    )\n",
    "\n",
    "    # Reshape data\n",
    "    test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "    print(f\"Test data shape: {test_d.shape}\")\n",
    "\n",
    "    # Create dataset\n",
    "    test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=3, collate_fn=test_dataset.collate_fn)\n",
    "    \n",
    "    # Save the prepared data\n",
    "    save_path = f'prepared_test_data_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.npz'\n",
    "    np.savez_compressed(save_path, \n",
    "                       test_labels=test_labels,\n",
    "                       test_dict=test_dict,\n",
    "                       prepared_test_labels_timesteps=prepared_test_labels_timesteps,\n",
    "                       output_size=prepared_test_labels.shape[-1])\n",
    "    \n",
    "    print(f\"Saved prepared data to {save_path}\")\n",
    "    \n",
    "    return test_loader, save_path\n",
    "\n",
    "def run_model_inference(test_loader, prepared_data_file, model_path=None, config=None):\n",
    "    \"\"\"\n",
    "    Run model inference using prepared data loader\n",
    "    \"\"\"\n",
    "    # Load prepared data info\n",
    "    data_info = np.load(prepared_data_file, allow_pickle=True)\n",
    "    config[\"output_size\"] = int(data_info['output_size'])\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load model\n",
    "    model = config[\"model\"](config)\n",
    "    model = model.to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # Evaluate model\n",
    "    model.eval()\n",
    "    test_pred = []\n",
    "    test_loss = 0.0\n",
    "    progress_bar = tqdm(test_loader, desc=f\"Test\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_d, batch_lbs in progress_bar:\n",
    "            with torch.amp.autocast(device_type=\"cuda\"):\n",
    "                batch_d = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                batch_d = model(batch_d)\n",
    "                loss = correlation_coefficient_loss(batch_d, batch_lbs)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_pred.extend(batch_d.float().cpu().numpy())\n",
    "            \n",
    "            progress_bar.set_postfix({'test loss: ': f'{test_loss/(progress_bar.n+1):.4f}'})\n",
    "            \n",
    "            del loss, batch_d, batch_lbs\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    \n",
    "    \n",
    "    # Get shape from saved data\n",
    "    prepared_test_labels_timesteps = data_info['prepared_test_labels_timesteps']\n",
    "    test_labels=data_info['test_labels']\n",
    "    test_dict=data_info['test_dict'].item()\n",
    "    test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        # Calculate metrics\n",
    "    test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "    test_pred_flat = concatenate_prediction(test_labels, test_pred, prepared_test_labels_timesteps, test_dict)\n",
    "    test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\nEvaluation completed.\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Pearson Coefficient (flattened): {test_prc_coef:.4f}\")\n",
    "    # Save predictions and necessary data\n",
    "    save_path = f'model_predictions_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.npz'\n",
    "    np.savez_compressed(save_path,\n",
    "                       predictions=test_pred,\n",
    "                       test_labels=data_info['test_labels'],\n",
    "                       test_dict=data_info['test_dict'],\n",
    "                       prepared_test_labels_timesteps=prepared_test_labels_timesteps,\n",
    "                       test_loss=test_loss)\n",
    "    \n",
    "    print(f\"Saved predictions to {save_path}\")\n",
    "    return save_path\n",
    "\n",
    "def calculate_metrics(predictions_file, run_dir=None):\n",
    "    \"\"\"\n",
    "    Calculate metrics from saved predictions\n",
    "    \"\"\"\n",
    "    if run_dir is None:\n",
    "        run_dir = create_run_directory()\n",
    "    \n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    # Load saved predictions and data\n",
    "    data = np.load(predictions_file, allow_pickle=True)\n",
    "    test_pred = data['predictions']\n",
    "    test_labels = data['test_labels']\n",
    "    test_dict = data['test_dict'].item()  # Convert numpy object array to dict\n",
    "    prepared_test_labels_timesteps = data['prepared_test_labels_timesteps']\n",
    "    test_loss = float(data['test_loss'])\n",
    "\n",
    "    # Calculate metrics\n",
    "    test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "    test_pred_flat = concatenate_prediction(test_labels, test_pred, prepared_test_labels_timesteps, test_dict)\n",
    "    test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\nEvaluation completed.\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Pearson Coefficient (flattened): {test_prc_coef:.4f}\")\n",
    "\n",
    "    # Log with tensorboard\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_scalar(\"Test/loss\", test_loss, 0)\n",
    "    writer.add_scalar(\"Test/pearson_coef\", test_prc_coef, 0)\n",
    "    \n",
    "    test_table = \"| Metric | Value |\\n\" \\\n",
    "                 \"|--------|-------|\\n\" \\\n",
    "                 f\"| Test Loss | {test_loss:.4f} |\\n\" \\\n",
    "                 f\"| Test Pearson Coefficient | {test_prc_coef:.4f} |\\n\"\n",
    "    writer.add_text(\"Test_Metrics\", test_table)\n",
    "    writer.close()\n",
    "\n",
    "    # Save results to CSV\n",
    "    results_df = pd.DataFrame({\n",
    "        'Test_Loss': [test_loss],\n",
    "        'Test_Pearson_Coefficient': [test_prc_coef]\n",
    "    })\n",
    "    csv_path = os.path.join(run_dir, 'test_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Results saved to {csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (576, 480000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/transformers/configuration_utils.py:306: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "/scratch-local/gdwildt.9115475/ipykernel_148366/45795489.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "Testing best_model_fold1: 100%|██████████| 20/20 [00:11<00:00,  1.71it/s, test loss=0.2319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 Results:\n",
      "Test Loss: 0.2319\n",
      "Accuracy (original): 0.7881\n",
      "Accuracy (gaussian): 0.7883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing best_model_fold2: 100%|██████████| 20/20 [00:10<00:00,  1.83it/s, test loss=0.2409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2 Results:\n",
      "Test Loss: 0.2409\n",
      "Accuracy (original): 0.7831\n",
      "Accuracy (gaussian): 0.7833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing best_model_fold4: 100%|██████████| 20/20 [00:10<00:00,  1.85it/s, test loss=0.2181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 Results:\n",
      "Test Loss: 0.2181\n",
      "Accuracy (original): 0.7973\n",
      "Accuracy (gaussian): 0.7975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing best_model_fold3: 100%|██████████| 20/20 [00:10<00:00,  1.82it/s, test loss=0.2214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3 Results:\n",
      "Test Loss: 0.2214\n",
      "Accuracy (original): 0.7974\n",
      "Accuracy (gaussian): 0.7976\n",
      "\n",
      "Results saved to pt_eval_batch/20241219-145753/evaluation_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from transformers import Wav2Vec2Processor,Wav2Vec2FeatureExtractor,AutoModel\n",
    "from tensorboardX import SummaryWriter\n",
    "from pt_utils import load_data, prepare_data, reshaping_data_for_model, unsplit_data_ogsize\n",
    "from pt_dataset import BreathingDataset\n",
    "import scipy.stats\n",
    "from torch.cuda.amp import autocast\n",
    "import glob\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_eval_batch\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def evaluate_model(model_path, test_loader, config, device, prepared_test_labels_timesteps, test_labels, test_dict, window_size, step_size):\n",
    "    # Load model\n",
    "    model = config[\"model\"](config)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    test_pred = []\n",
    "    test_loss = 0.0\n",
    "    progress_bar = tqdm(test_loader, desc=f\"Testing {os.path.basename(model_path)}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_d, batch_lbs in progress_bar:\n",
    "            with torch.amp.autocast(device_type=\"cuda\"):\n",
    "                batch_d = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                batch_d = model(batch_d)\n",
    "                loss = correlation_coefficient_loss(batch_d, batch_lbs)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_pred.extend(batch_d.float().cpu().numpy())\n",
    "            progress_bar.set_postfix({'test loss': f'{test_loss/(progress_bar.n+1):.4f}'})\n",
    "            \n",
    "            del loss, batch_d, batch_lbs\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "    test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "    \n",
    "    # Calculate accuracies for different methods\n",
    "    accuracies = {}\n",
    "    for method in ['original', 'gaussian']:\n",
    "        average = unsplit_data(test_pred, window_size, step_size, method, test_ground_truth.shape[-1])\n",
    "        accuracy = _calculate_flattened_accuracy(average, test_ground_truth)\n",
    "        accuracies[method] = accuracy\n",
    "    \n",
    "    return test_loss, accuracies\n",
    "\n",
    "def batch_evaluate(path_to_test_data, path_to_test_labels, models_folder, window_size=16, step_size=6, batch_size=10, config=None, processor= None):\n",
    "    run_dir = create_run_directory()\n",
    "    results_path = os.path.join(run_dir, 'evaluation_results.csv')\n",
    "    \n",
    "    # Load and prepare test data\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_test_data, path_to_test_labels, 'test')\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(\n",
    "        test_data, test_labels, test_dict, frame_rate, size_window=window_size * 16000, step_for_window=step_size * 16000\n",
    "    )\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    config[\"output_size\"] = prepared_test_labels.shape[-1]\n",
    "    \n",
    "    # Reshape data\n",
    "    test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "    print(f\"Test data shape: {test_d.shape}\")\n",
    "    \n",
    "    # Create dataset and DataLoader\n",
    "    test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=3, collate_fn=test_dataset.collate_fn)\n",
    "    \n",
    "    # Find all model files\n",
    "    model_files = glob.glob(os.path.join(models_folder, 'best_model_fold*'))\n",
    "    results = []\n",
    "    \n",
    "    # Evaluate each model\n",
    "    for model_path in model_files:\n",
    "        fold_num = int(model_path.split('fold')[-1])\n",
    "        test_loss, accuracies = evaluate_model(\n",
    "            model_path, test_loader, config, device,\n",
    "            prepared_test_labels_timesteps, test_labels,\n",
    "            test_dict, window_size, step_size\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'fold': fold_num,\n",
    "            'model_path': model_path,\n",
    "            'test_loss': test_loss\n",
    "        }\n",
    "        result.update({f'accuracy_{method}': acc for method, acc in accuracies.items()})\n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"\\nFold {fold_num} Results:\")\n",
    "        print(f\"Test Loss: {test_loss:.4f}\")\n",
    "        for method, acc in accuracies.items():\n",
    "            print(f\"Accuracy ({method}): {acc:.4f}\")\n",
    "    \n",
    "    # Create DataFrame and calculate averages\n",
    "    results_df = pd.DataFrame(results)\n",
    "    averages = results_df.select_dtypes(include=[np.number]).mean()\n",
    "    std_devs = results_df.select_dtypes(include=[np.number]).std()\n",
    "    \n",
    "    # Add average and std dev rows\n",
    "    results_df.loc['average'] = averages\n",
    "    results_df.loc['std_dev'] = std_devs\n",
    "    \n",
    "    # Save results\n",
    "    results_df.to_csv(results_path, index=True)\n",
    "    print(f\"\\nResults saved to {results_path}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Model configuration (using RespBertCNNModel as example)\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ls960-ft\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"RespBertLSTM\": {\n",
    "            'model': RespBertLSTM,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 256,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  \n",
    "        },\n",
    "        \"RespBertAttention\": {\n",
    "            'model' : RespBertAttention,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 512,\n",
    "            \"n_attion\": 2,\n",
    "            \"output_size\": None  \n",
    "        },\n",
    "\n",
    "        \"RespBertCNN_12\": {\n",
    "            'model' : RespBertCNN,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 256,\n",
    "            \"output_size\": None,\n",
    "            \"number_finetune\": 12 \n",
    "        },\n",
    "    \n",
    "        \"RespBertCNN_16\": {\n",
    "            'model' : RespBertCNN,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 256,\n",
    "            \"output_size\": None ,\n",
    "            \"number_finetune\": 16 \n",
    "\n",
    "        }\n",
    "    }\n",
    "    path = \"../DATA/\"\n",
    "    \n",
    "    \n",
    "    # Evaluation parameters\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    batch_size = 30\n",
    "    model_name = \"Wav2Vec2ConvLSTMModel\"\n",
    "    config = model_config[model_name]\n",
    "    #processor = Wav2vec2F.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "    models_folder = f\"./pt_runs/{model_name}/\"  # Folder containing all model files\n",
    "\n",
    "    results = batch_evaluate(\n",
    "        path_to_test_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_test_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        models_folder=models_folder,\n",
    "        window_size=window_size,\n",
    "        step_size=step_size,\n",
    "        batch_size=batch_size,\n",
    "        config=config,\n",
    "        processor=processor\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/glenn/Downloads/ComParE2020_Breathing/lab/labels.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/glenn/Downloads/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#path = \"../DATA/\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m test_loader, prepared_data_file \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_test_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43mpath_to_test_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mComParE2020_Breathing/wav/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43mpath_to_test_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mComParE2020_Breathing/lab/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m calculate_metrics(predictions_file)\n",
      "Cell \u001b[0;32mIn[1], line 51\u001b[0m, in \u001b[0;36mprepare_test_datasets\u001b[0;34m(path_to_test_data, path_to_test_labels, window_size, step_size, batch_size, processor)\u001b[0m\n\u001b[1;32m     48\u001b[0m step_sequence \u001b[38;5;241m=\u001b[39m step_size\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Load and prepare test data\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m test_data, test_labels, test_dict, frame_rate \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_test_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_to_test_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps \u001b[38;5;241m=\u001b[39m prepare_data(\n\u001b[1;32m     53\u001b[0m     test_data, test_labels, test_dict, frame_rate, \n\u001b[1;32m     54\u001b[0m     length_sequence \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m16000\u001b[39m, step_sequence \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m16000\u001b[39m\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Reshape data\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/home3/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_utils.py:261\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(path_to_data, path_to_labels, prefix)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(path_to_data, path_to_labels, prefix):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# labels\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     labels\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_labels\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mloc[labels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(prefix)]\n\u001b[1;32m    263\u001b[0m     labels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper_belt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mlabels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper_belt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/glenn/Downloads/ComParE2020_Breathing/lab/labels.csv'"
     ]
    }
   ],
   "source": [
    "# #predictions_file = \"/home/glenn/Documents/GitHub/Master_thesis/1dcnn_breathing_prediction/model_predictions_20241023-190407.npz\"\n",
    "# #path = \"/home/glenn/Downloads/\"\n",
    "# path = \"../DATA/\"\n",
    "\n",
    "# test_loader, prepared_data_file = prepare_test_datasets(\n",
    "# path_to_test_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "# path_to_test_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "# processor=None\n",
    "# )\n",
    "\n",
    "# #calculate_metrics(predictions_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
