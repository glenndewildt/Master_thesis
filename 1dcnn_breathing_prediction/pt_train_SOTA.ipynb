{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to thesis (Python 3.11.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b36ae33a-40a5-453e-8d35-41c13dbe70ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/128: 100%|██████████| 7/7 [00:35<00:00,  5.11s/it, train_loss=1.0063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128 - Train Loss: 1.0063, Val Loss: 1.0034, Val Pearson: -0.0086\n",
      "Validation loss improved from inf to 1.0034. Saving best model...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:603] . unexpected pos 98176 vs 98064",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/serialization.py:652\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 652\u001b[0m     _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    653\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/serialization.py:886\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    885\u001b[0m num_bytes \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39mnbytes()\n\u001b[0;32m--> 886\u001b[0m zip_file\u001b[39m.\u001b[39;49mwrite_record(name, storage, num_bytes)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:778] . PytorchStreamWriter failed writing file data/1: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:333\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[39m## same wav2vec2 base model and pipeline used in the paper\u001b[39;00m\n\u001b[1;32m    331\u001b[0m processor \u001b[39m=\u001b[39m AutoProcessor\u001b[39m.\u001b[39mfrom_pretrained(config[\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 333\u001b[0m train(\n\u001b[1;32m    334\u001b[0m     path_to_data\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/wav/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    335\u001b[0m     path_to_labels\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/lab/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    336\u001b[0m     window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    337\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    338\u001b[0m     config \u001b[39m=\u001b[39;49m config,\n\u001b[1;32m    339\u001b[0m     step_size\u001b[39m=\u001b[39;49mstep_size,\n\u001b[1;32m    340\u001b[0m     data_parts\u001b[39m=\u001b[39;49m data_parts ,\n\u001b[1;32m    341\u001b[0m     early_stopping_patience\u001b[39m=\u001b[39;49m early_stopping_patience,\n\u001b[1;32m    342\u001b[0m     epochs\u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    343\u001b[0m     processor \u001b[39m=\u001b[39;49m processor\n\u001b[1;32m    344\u001b[0m )\n",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:197\u001b[0m\n\u001b[1;32m    194\u001b[0m     early_stopping_counter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    196\u001b[0m     \u001b[39m# Save the best model\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m     torch\u001b[39m.\u001b[39;49msave(model\u001b[39m.\u001b[39;49mstate_dict(), best_model_path)\n\u001b[1;32m    198\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     early_stopping_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/serialization.py:651\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    648\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    650\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 651\u001b[0m     \u001b[39mwith\u001b[39;49;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;49;00m opened_zipfile:\n\u001b[1;32m    652\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    653\u001b[0m         \u001b[39mreturn\u001b[39;49;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/serialization.py:499\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_like\u001b[39m.\u001b[39;49mwrite_end_of_file()\n\u001b[1;32m    500\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_stream \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    501\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_stream\u001b[39m.\u001b[39mclose()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:603] . unexpected pos 98176 vs 98064"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import AutoModel, AdamW, get_cosine_schedule_with_warmup\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "# Function to gradually unfreeze layers\n",
    "def gradually_unfreeze(model, epoch, total_epochs, initial_unfreeze=2):\n",
    "    total_layers = len(model.wav_model.encoder.layers)\n",
    "    layers_to_unfreeze = initial_unfreeze + (epoch * (total_layers - initial_unfreeze) // total_epochs)\n",
    "    model.unfreeze_last_n_blocks(layers_to_unfreeze)\n",
    "    \n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate)       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ls960-ft\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 128\n",
    "    batch_size = 128\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 15\n",
    "    \n",
    "    config = model_config[\"VRBModel\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    \n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted thesis (Python 3.11.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55a9242c-430e-4a4c-839b-f3fe99d8e856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/128: 100%|██████████| 7/7 [00:37<00:00,  5.30s/it, train_loss=1.0028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128 - Train Loss: 1.0028, Val Loss: 1.0063, Val Pearson: -0.0148\n",
      "Validation loss improved from inf to 1.0063. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/128: 100%|██████████| 7/7 [00:34<00:00,  4.87s/it, train_loss=0.9925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/128 - Train Loss: 0.9925, Val Loss: 1.0088, Val Pearson: -0.0156\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/128: 100%|██████████| 7/7 [00:35<00:00,  5.02s/it, train_loss=0.9882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/128 - Train Loss: 0.9882, Val Loss: 1.0104, Val Pearson: -0.0165\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/128: 100%|██████████| 7/7 [00:36<00:00,  5.16s/it, train_loss=0.9850]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/128 - Train Loss: 0.9850, Val Loss: 1.0110, Val Pearson: -0.0160\n",
      "Validation loss did not improve for 3 epochs.\n",
      "Early stopping triggered at epoch 4. Loading best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-4bad5d9317cb>:208: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Validation Pearson Coefficient  acc: -0.0062912702560424805\n",
      "  Validation Pearson Coefficient flat acc: -0.014798802708906985\n",
      "  Test acc: -0.009982633590698287\n",
      "  Test Pearson Coefficient acc(flattened): -0.01610076019429338\n",
      "Fold 2/4\n",
      "(900, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/128:  25%|██▌       | 2/8 [00:12<00:35,  5.99s/it, train_loss=1.0000]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate)       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ls960-ft\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 128\n",
    "    batch_size = 128\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 3\n",
    "    \n",
    "    config = model_config[\"VRBModel\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    \n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted thesis (Python 3.11.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1e173d-0d97-4bb0-8fe8-5fd55244ea94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/128: 100%|██████████| 7/7 [00:33<00:00,  4.85s/it, train_loss=1.0058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128 - Train Loss: 1.0058, Val Loss: 1.0051, Val Pearson: -0.0082\n",
      "Validation loss improved from inf to 1.0051. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/128: 100%|██████████| 7/7 [00:30<00:00,  4.31s/it, train_loss=0.9950]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/128 - Train Loss: 0.9950, Val Loss: 1.0087, Val Pearson: -0.0122\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/128: 100%|██████████| 7/7 [00:30<00:00,  4.42s/it, train_loss=0.9901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/128 - Train Loss: 0.9901, Val Loss: 1.0102, Val Pearson: -0.0132\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/128: 100%|██████████| 7/7 [00:31<00:00,  4.46s/it, train_loss=0.9857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/128 - Train Loss: 0.9857, Val Loss: 1.0108, Val Pearson: -0.0135\n",
      "Validation loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/128: 100%|██████████| 7/7 [00:28<00:00,  4.10s/it, train_loss=0.9881]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:333\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[39m## same wav2vec2 base model and pipeline used in the paper\u001b[39;00m\n\u001b[1;32m    331\u001b[0m processor \u001b[39m=\u001b[39m AutoProcessor\u001b[39m.\u001b[39mfrom_pretrained(config[\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 333\u001b[0m train(\n\u001b[1;32m    334\u001b[0m     path_to_data\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/wav/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    335\u001b[0m     path_to_labels\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/lab/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    336\u001b[0m     window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    337\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    338\u001b[0m     config \u001b[39m=\u001b[39;49m config,\n\u001b[1;32m    339\u001b[0m     step_size\u001b[39m=\u001b[39;49mstep_size,\n\u001b[1;32m    340\u001b[0m     data_parts\u001b[39m=\u001b[39;49m data_parts ,\n\u001b[1;32m    341\u001b[0m     early_stopping_patience\u001b[39m=\u001b[39;49m early_stopping_patience,\n\u001b[1;32m    342\u001b[0m     epochs\u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    343\u001b[0m     processor \u001b[39m=\u001b[39;49m processor\n\u001b[1;32m    344\u001b[0m )\n",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:176\u001b[0m\n\u001b[1;32m    174\u001b[0m val_ground_truth \u001b[39m=\u001b[39m _get_ground_truth_labels([all_dict[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m val_index], all_labels)\n\u001b[1;32m    175\u001b[0m val_pred_flat \u001b[39m=\u001b[39m unsplit_data_ogsize(val_pred, window_size, step_sequence, \u001b[39m25\u001b[39m, val_ground_truth\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m--> 176\u001b[0m val_prc_coef \u001b[39m=\u001b[39m _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n\u001b[1;32m    178\u001b[0m \u001b[39m# Accumulate metrics for this fold and epoch\u001b[39;00m\n\u001b[1;32m    179\u001b[0m train_acc\u001b[39m.\u001b[39mappend(\u001b[39m1\u001b[39m\u001b[39m-\u001b[39m train_loss)\n",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:31\u001b[0m\n\u001b[1;32m     29\u001b[0m s_acc \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(ground_truth_labels)):\n\u001b[0;32m---> 31\u001b[0m     s, _ \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49mstats\u001b[39m.\u001b[39;49mpearsonr(average[b], ground_truth_labels[b])\n\u001b[1;32m     32\u001b[0m     s_acc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m s\n\u001b[1;32m     33\u001b[0m \u001b[39mreturn\u001b[39;00m s_acc \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(ground_truth_labels)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4451\u001b[0m, in \u001b[0;36mpearsonr\u001b[0;34m(x, y, alternative)\u001b[0m\n\u001b[1;32m   4446\u001b[0m ym \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mastype(dtype) \u001b[39m-\u001b[39m ymean\n\u001b[1;32m   4448\u001b[0m \u001b[39m# Unlike np.linalg.norm or the expression sqrt((xm*xm).sum()),\u001b[39;00m\n\u001b[1;32m   4449\u001b[0m \u001b[39m# scipy.linalg.norm(xm) does not overflow if xm is, for example,\u001b[39;00m\n\u001b[1;32m   4450\u001b[0m \u001b[39m# [-5e210, 5e210, 3e200, -3e200]\u001b[39;00m\n\u001b[0;32m-> 4451\u001b[0m normxm \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39;49mnorm(xm)\n\u001b[1;32m   4452\u001b[0m normym \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39mnorm(ym)\n\u001b[1;32m   4454\u001b[0m threshold \u001b[39m=\u001b[39m \u001b[39m1e-13\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/scipy/linalg/_misc.py:146\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(a, ord, axis, keepdims, check_finite)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39m# Differs from numpy only in non-finite handling and the use of blas.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m check_finite:\n\u001b[0;32m--> 146\u001b[0m     a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray_chkfinite(a)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(a)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/numpy/lib/function_base.py:628\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    626\u001b[0m a \u001b[39m=\u001b[39m asarray(a, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder)\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m a\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mchar \u001b[39min\u001b[39;00m typecodes[\u001b[39m'\u001b[39m\u001b[39mAllFloat\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(a)\u001b[39m.\u001b[39mall():\n\u001b[0;32m--> 628\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    629\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39marray must not contain infs or NaNs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    630\u001b[0m \u001b[39mreturn\u001b[39;00m a\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate)       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ls960-ft\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 128\n",
    "    batch_size = 128\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"VRBModel\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    \n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted thesis (Python 3.11.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa848a5-ded7-40b5-a035-b92479c16ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/128: 100%|██████████| 14/14 [00:30<00:00,  2.16s/it, train_loss=1.0073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128 - Train Loss: 1.0073, Val Loss: 0.9901, Val Pearson: -0.0009\n",
      "Validation loss improved from inf to 0.9901. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/128: 100%|██████████| 14/14 [00:29<00:00,  2.13s/it, train_loss=0.9927]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate)       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ls960-ft\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 128\n",
    "    batch_size = 64\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"VRBModel\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    \n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted thesis (Python 3.11.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "976902fa-86f8-4a8e-991f-fe930f19d603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/128: 100%|██████████| 14/14 [00:29<00:00,  2.09s/it, train_loss=1.0013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128 - Train Loss: 1.0013, Val Loss: 0.9151, Val Pearson: 0.1194\n",
      "Validation loss improved from inf to 0.9151. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/128: 100%|██████████| 14/14 [00:29<00:00,  2.13s/it, train_loss=0.7097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/128 - Train Loss: 0.7097, Val Loss: 0.5928, Val Pearson: 0.4455\n",
      "Validation loss improved from 0.9151 to 0.5928. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/128: 100%|██████████| 14/14 [00:29<00:00,  2.08s/it, train_loss=0.5055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/128 - Train Loss: 0.5055, Val Loss: 0.4834, Val Pearson: 0.5210\n",
      "Validation loss improved from 0.5928 to 0.4834. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/128: 100%|██████████| 14/14 [00:30<00:00,  2.16s/it, train_loss=0.4334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/128 - Train Loss: 0.4334, Val Loss: 0.4171, Val Pearson: 0.5944\n",
      "Validation loss improved from 0.4834 to 0.4171. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/128: 100%|██████████| 14/14 [00:29<00:00,  2.12s/it, train_loss=0.3624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/128 - Train Loss: 0.3624, Val Loss: 0.2834, Val Pearson: 0.7105\n",
      "Validation loss improved from 0.4171 to 0.2834. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/128: 100%|██████████| 14/14 [00:29<00:00,  2.14s/it, train_loss=0.3349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/128 - Train Loss: 0.3349, Val Loss: 0.2685, Val Pearson: 0.7146\n",
      "Validation loss improved from 0.2834 to 0.2685. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/128: 100%|██████████| 14/14 [00:30<00:00,  2.17s/it, train_loss=0.2979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/128 - Train Loss: 0.2979, Val Loss: 0.2365, Val Pearson: 0.7526\n",
      "Validation loss improved from 0.2685 to 0.2365. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/128: 100%|██████████| 14/14 [00:29<00:00,  2.11s/it, train_loss=0.3526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/128 - Train Loss: 0.3526, Val Loss: 0.3089, Val Pearson: 0.7217\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/128: 100%|██████████| 14/14 [00:30<00:00,  2.15s/it, train_loss=0.3324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/128 - Train Loss: 0.3324, Val Loss: 0.3153, Val Pearson: 0.6836\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/128: 100%|██████████| 14/14 [00:29<00:00,  2.14s/it, train_loss=0.3091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/128 - Train Loss: 0.3091, Val Loss: 0.2332, Val Pearson: 0.7531\n",
      "Validation loss improved from 0.2365 to 0.2332. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/128: 100%|██████████| 14/14 [00:29<00:00,  2.10s/it, train_loss=0.2709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/128 - Train Loss: 0.2709, Val Loss: 0.2260, Val Pearson: 0.7607\n",
      "Validation loss improved from 0.2332 to 0.2260. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/128: 100%|██████████| 14/14 [00:30<00:00,  2.16s/it, train_loss=0.2591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/128 - Train Loss: 0.2591, Val Loss: 0.2187, Val Pearson: 0.7679\n",
      "Validation loss improved from 0.2260 to 0.2187. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/128: 100%|██████████| 14/14 [00:29<00:00,  2.11s/it, train_loss=0.2449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/128 - Train Loss: 0.2449, Val Loss: 0.2199, Val Pearson: 0.7693\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/128: 100%|██████████| 14/14 [00:29<00:00,  2.11s/it, train_loss=0.2332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/128 - Train Loss: 0.2332, Val Loss: 0.2211, Val Pearson: 0.7729\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/128: 100%|██████████| 14/14 [00:29<00:00,  2.09s/it, train_loss=0.2242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/128 - Train Loss: 0.2242, Val Loss: 0.2265, Val Pearson: 0.7667\n",
      "Validation loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/128: 100%|██████████| 14/14 [00:29<00:00,  2.09s/it, train_loss=0.2087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/128 - Train Loss: 0.2087, Val Loss: 0.2305, Val Pearson: 0.7674\n",
      "Validation loss did not improve for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/128: 100%|██████████| 14/14 [00:30<00:00,  2.16s/it, train_loss=0.1980]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/128 - Train Loss: 0.1980, Val Loss: 0.2346, Val Pearson: 0.7650\n",
      "Validation loss did not improve for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/128: 100%|██████████| 14/14 [00:29<00:00,  2.09s/it, train_loss=0.1787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/128 - Train Loss: 0.1787, Val Loss: 0.2376, Val Pearson: 0.7634\n",
      "Validation loss did not improve for 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/128: 100%|██████████| 14/14 [00:29<00:00,  2.09s/it, train_loss=0.1893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/128 - Train Loss: 0.1893, Val Loss: 0.2489, Val Pearson: 0.7555\n",
      "Validation loss did not improve for 7 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/128: 100%|██████████| 14/14 [00:30<00:00,  2.15s/it, train_loss=0.1655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/128 - Train Loss: 0.1655, Val Loss: 0.2619, Val Pearson: 0.7570\n",
      "Validation loss did not improve for 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/128: 100%|██████████| 14/14 [00:30<00:00,  2.15s/it, train_loss=0.1469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/128 - Train Loss: 0.1469, Val Loss: 0.2542, Val Pearson: 0.7544\n",
      "Validation loss did not improve for 9 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/128: 100%|██████████| 14/14 [00:35<00:00,  2.51s/it, train_loss=0.1565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/128 - Train Loss: 0.1565, Val Loss: 0.3305, Val Pearson: 0.6708\n",
      "Validation loss did not improve for 10 epochs.\n",
      "Early stopping triggered at epoch 22. Loading best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-38649e80a240>:208: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Validation Pearson Coefficient  acc: 0.7812866866588593\n",
      "  Validation Pearson Coefficient flat acc: 0.7679455613693423\n",
      "  Test acc: 0.7636429203881158\n",
      "  Test Pearson Coefficient acc(flattened): 0.7713440330556783\n",
      "Fold 2/4\n",
      "(900, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/128: 100%|██████████| 15/15 [00:36<00:00,  2.44s/it, train_loss=0.9922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128 - Train Loss: 0.9922, Val Loss: 0.8500, Val Pearson: 0.2306\n",
      "Validation loss improved from inf to 0.8500. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/128: 100%|██████████| 15/15 [00:36<00:00,  2.42s/it, train_loss=0.7321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/128 - Train Loss: 0.7321, Val Loss: 0.6291, Val Pearson: 0.4245\n",
      "Validation loss improved from 0.8500 to 0.6291. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/128: 100%|██████████| 15/15 [00:35<00:00,  2.40s/it, train_loss=0.5548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/128 - Train Loss: 0.5548, Val Loss: 0.6478, Val Pearson: 0.4089\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/128: 100%|██████████| 15/15 [00:36<00:00,  2.41s/it, train_loss=0.4988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/128 - Train Loss: 0.4988, Val Loss: 0.5645, Val Pearson: 0.4823\n",
      "Validation loss improved from 0.6291 to 0.5645. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/128: 100%|██████████| 15/15 [00:36<00:00,  2.41s/it, train_loss=0.4019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/128 - Train Loss: 0.4019, Val Loss: 0.4358, Val Pearson: 0.6042\n",
      "Validation loss improved from 0.5645 to 0.4358. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/128: 100%|██████████| 15/15 [00:36<00:00,  2.43s/it, train_loss=0.3162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/128 - Train Loss: 0.3162, Val Loss: 0.3799, Val Pearson: 0.6587\n",
      "Validation loss improved from 0.4358 to 0.3799. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/128: 100%|██████████| 15/15 [00:35<00:00,  2.36s/it, train_loss=0.3066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/128 - Train Loss: 0.3066, Val Loss: 0.3795, Val Pearson: 0.6652\n",
      "Validation loss improved from 0.3799 to 0.3795. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/128: 100%|██████████| 15/15 [00:36<00:00,  2.42s/it, train_loss=0.3028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/128 - Train Loss: 0.3028, Val Loss: 0.3596, Val Pearson: 0.6771\n",
      "Validation loss improved from 0.3795 to 0.3596. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/128: 100%|██████████| 15/15 [00:35<00:00,  2.39s/it, train_loss=0.2726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/128 - Train Loss: 0.2726, Val Loss: 0.3581, Val Pearson: 0.6799\n",
      "Validation loss improved from 0.3596 to 0.3581. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/128: 100%|██████████| 15/15 [00:35<00:00,  2.39s/it, train_loss=0.2742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/128 - Train Loss: 0.2742, Val Loss: 0.3493, Val Pearson: 0.6840\n",
      "Validation loss improved from 0.3581 to 0.3493. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/128: 100%|██████████| 15/15 [00:35<00:00,  2.40s/it, train_loss=0.2616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/128 - Train Loss: 0.2616, Val Loss: 0.3404, Val Pearson: 0.6952\n",
      "Validation loss improved from 0.3493 to 0.3404. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/128: 100%|██████████| 15/15 [00:35<00:00,  2.40s/it, train_loss=0.2467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/128 - Train Loss: 0.2467, Val Loss: 0.3356, Val Pearson: 0.6991\n",
      "Validation loss improved from 0.3404 to 0.3356. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/128: 100%|██████████| 15/15 [00:36<00:00,  2.42s/it, train_loss=0.2388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/128 - Train Loss: 0.2388, Val Loss: 0.3318, Val Pearson: 0.7035\n",
      "Validation loss improved from 0.3356 to 0.3318. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/128: 100%|██████████| 15/15 [00:35<00:00,  2.35s/it, train_loss=0.2334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/128 - Train Loss: 0.2334, Val Loss: 0.3385, Val Pearson: 0.6996\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/128: 100%|██████████| 15/15 [00:35<00:00,  2.38s/it, train_loss=0.2372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/128 - Train Loss: 0.2372, Val Loss: 0.3337, Val Pearson: 0.7060\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/128: 100%|██████████| 15/15 [00:36<00:00,  2.42s/it, train_loss=0.2222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/128 - Train Loss: 0.2222, Val Loss: 0.3364, Val Pearson: 0.7023\n",
      "Validation loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/128: 100%|██████████| 15/15 [00:35<00:00,  2.39s/it, train_loss=0.2006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/128 - Train Loss: 0.2006, Val Loss: 0.3350, Val Pearson: 0.7040\n",
      "Validation loss did not improve for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/128: 100%|██████████| 15/15 [00:36<00:00,  2.43s/it, train_loss=0.1979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/128 - Train Loss: 0.1979, Val Loss: 0.3448, Val Pearson: 0.6972\n",
      "Validation loss did not improve for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/128: 100%|██████████| 15/15 [00:36<00:00,  2.44s/it, train_loss=0.1853]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/128 - Train Loss: 0.1853, Val Loss: 0.3313, Val Pearson: 0.7106\n",
      "Validation loss improved from 0.3318 to 0.3313. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/128: 100%|██████████| 15/15 [00:35<00:00,  2.39s/it, train_loss=0.1714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/128 - Train Loss: 0.1714, Val Loss: 0.3334, Val Pearson: 0.7085\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/128: 100%|██████████| 15/15 [00:36<00:00,  2.45s/it, train_loss=0.1797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/128 - Train Loss: 0.1797, Val Loss: 0.3330, Val Pearson: 0.7110\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/128: 100%|██████████| 15/15 [00:36<00:00,  2.40s/it, train_loss=0.1717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/128 - Train Loss: 0.1717, Val Loss: 0.3511, Val Pearson: 0.6980\n",
      "Validation loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/128: 100%|██████████| 15/15 [00:36<00:00,  2.41s/it, train_loss=0.1531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/128 - Train Loss: 0.1531, Val Loss: 0.3450, Val Pearson: 0.7057\n",
      "Validation loss did not improve for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/128: 100%|██████████| 15/15 [00:36<00:00,  2.43s/it, train_loss=0.1405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/128 - Train Loss: 0.1405, Val Loss: 0.3492, Val Pearson: 0.6911\n",
      "Validation loss did not improve for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/128: 100%|██████████| 15/15 [00:36<00:00,  2.42s/it, train_loss=0.1402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/128 - Train Loss: 0.1402, Val Loss: 0.3417, Val Pearson: 0.7076\n",
      "Validation loss did not improve for 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/128: 100%|██████████| 15/15 [00:35<00:00,  2.38s/it, train_loss=0.1256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/128 - Train Loss: 0.1256, Val Loss: 0.3577, Val Pearson: 0.6935\n",
      "Validation loss did not improve for 7 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/128: 100%|██████████| 15/15 [00:36<00:00,  2.45s/it, train_loss=0.1106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/128 - Train Loss: 0.1106, Val Loss: 0.3616, Val Pearson: 0.6930\n",
      "Validation loss did not improve for 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/128: 100%|██████████| 15/15 [00:35<00:00,  2.38s/it, train_loss=0.1042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/128 - Train Loss: 0.1042, Val Loss: 0.3602, Val Pearson: 0.6950\n",
      "Validation loss did not improve for 9 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/128: 100%|██████████| 15/15 [00:36<00:00,  2.42s/it, train_loss=0.0941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/128 - Train Loss: 0.0941, Val Loss: 0.3685, Val Pearson: 0.6895\n",
      "Validation loss did not improve for 10 epochs.\n",
      "Early stopping triggered at epoch 29. Loading best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-38649e80a240>:208: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2:\n",
      "  Validation Pearson Coefficient  acc: 0.6686662793159485\n",
      "  Validation Pearson Coefficient flat acc: 0.7105616516151114\n",
      "  Test acc: 0.7758767339918349\n",
      "  Test Pearson Coefficient acc(flattened): 0.7932222368250055\n",
      "Fold 3/4\n",
      "(900, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/128: 100%|██████████| 15/15 [00:35<00:00,  2.39s/it, train_loss=0.9908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128 - Train Loss: 0.9908, Val Loss: 0.9003, Val Pearson: 0.1474\n",
      "Validation loss improved from inf to 0.9003. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/128: 100%|██████████| 15/15 [00:36<00:00,  2.45s/it, train_loss=0.7278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/128 - Train Loss: 0.7278, Val Loss: 0.6272, Val Pearson: 0.4103\n",
      "Validation loss improved from 0.9003 to 0.6272. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/128: 100%|██████████| 15/15 [00:37<00:00,  2.50s/it, train_loss=0.4942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/128 - Train Loss: 0.4942, Val Loss: 0.5335, Val Pearson: 0.4629\n",
      "Validation loss improved from 0.6272 to 0.5335. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/128: 100%|██████████| 15/15 [00:37<00:00,  2.47s/it, train_loss=0.4095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/128 - Train Loss: 0.4095, Val Loss: 0.4726, Val Pearson: 0.5416\n",
      "Validation loss improved from 0.5335 to 0.4726. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/128: 100%|██████████| 15/15 [00:36<00:00,  2.43s/it, train_loss=0.4843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/128 - Train Loss: 0.4843, Val Loss: 0.6561, Val Pearson: 0.4332\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/128: 100%|██████████| 15/15 [00:36<00:00,  2.42s/it, train_loss=0.4372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/128 - Train Loss: 0.4372, Val Loss: 0.4900, Val Pearson: 0.5405\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/128: 100%|██████████| 15/15 [00:35<00:00,  2.37s/it, train_loss=0.3221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/128 - Train Loss: 0.3221, Val Loss: 0.4006, Val Pearson: 0.5904\n",
      "Validation loss improved from 0.4726 to 0.4006. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/128: 100%|██████████| 15/15 [00:36<00:00,  2.42s/it, train_loss=0.2770]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/128 - Train Loss: 0.2770, Val Loss: 0.3753, Val Pearson: 0.6115\n",
      "Validation loss improved from 0.4006 to 0.3753. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/128: 100%|██████████| 15/15 [00:36<00:00,  2.41s/it, train_loss=0.2571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/128 - Train Loss: 0.2571, Val Loss: 0.3599, Val Pearson: 0.6273\n",
      "Validation loss improved from 0.3753 to 0.3599. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/128: 100%|██████████| 15/15 [00:36<00:00,  2.41s/it, train_loss=0.2526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/128 - Train Loss: 0.2526, Val Loss: 0.3531, Val Pearson: 0.6344\n",
      "Validation loss improved from 0.3599 to 0.3531. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/128: 100%|██████████| 15/15 [00:36<00:00,  2.41s/it, train_loss=0.2343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/128 - Train Loss: 0.2343, Val Loss: 0.3542, Val Pearson: 0.6351\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/128: 100%|██████████| 15/15 [00:37<00:00,  2.47s/it, train_loss=0.2339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/128 - Train Loss: 0.2339, Val Loss: 0.3478, Val Pearson: 0.6449\n",
      "Validation loss improved from 0.3531 to 0.3478. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/128: 100%|██████████| 15/15 [00:36<00:00,  2.41s/it, train_loss=0.2336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/128 - Train Loss: 0.2336, Val Loss: 0.3458, Val Pearson: 0.6485\n",
      "Validation loss improved from 0.3478 to 0.3458. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/128: 100%|██████████| 15/15 [00:36<00:00,  2.45s/it, train_loss=0.2237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/128 - Train Loss: 0.2237, Val Loss: 0.3425, Val Pearson: 0.6523\n",
      "Validation loss improved from 0.3458 to 0.3425. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/128: 100%|██████████| 15/15 [00:35<00:00,  2.37s/it, train_loss=0.2124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/128 - Train Loss: 0.2124, Val Loss: 0.3416, Val Pearson: 0.6525\n",
      "Validation loss improved from 0.3425 to 0.3416. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/128: 100%|██████████| 15/15 [00:36<00:00,  2.42s/it, train_loss=0.2225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/128 - Train Loss: 0.2225, Val Loss: 0.3420, Val Pearson: 0.6531\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/128: 100%|██████████| 15/15 [00:36<00:00,  2.42s/it, train_loss=0.2128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/128 - Train Loss: 0.2128, Val Loss: 0.3448, Val Pearson: 0.6511\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/128: 100%|██████████| 15/15 [00:35<00:00,  2.39s/it, train_loss=0.2123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/128 - Train Loss: 0.2123, Val Loss: 0.3431, Val Pearson: 0.6546\n",
      "Validation loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/128: 100%|██████████| 15/15 [00:36<00:00,  2.42s/it, train_loss=0.2047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/128 - Train Loss: 0.2047, Val Loss: 0.3364, Val Pearson: 0.6595\n",
      "Validation loss improved from 0.3416 to 0.3364. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/128: 100%|██████████| 15/15 [00:35<00:00,  2.37s/it, train_loss=0.1929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/128 - Train Loss: 0.1929, Val Loss: 0.3379, Val Pearson: 0.6662\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/128: 100%|██████████| 15/15 [00:35<00:00,  2.36s/it, train_loss=0.1795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/128 - Train Loss: 0.1795, Val Loss: 0.3397, Val Pearson: 0.6624\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/128: 100%|██████████| 15/15 [00:36<00:00,  2.45s/it, train_loss=0.1752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/128 - Train Loss: 0.1752, Val Loss: 0.3454, Val Pearson: 0.6566\n",
      "Validation loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/128: 100%|██████████| 15/15 [00:36<00:00,  2.43s/it, train_loss=0.1756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/128 - Train Loss: 0.1756, Val Loss: 0.3769, Val Pearson: 0.6356\n",
      "Validation loss did not improve for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/128: 100%|██████████| 15/15 [00:35<00:00,  2.37s/it, train_loss=0.1678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/128 - Train Loss: 0.1678, Val Loss: 0.3370, Val Pearson: 0.6628\n",
      "Validation loss did not improve for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/128: 100%|██████████| 15/15 [00:36<00:00,  2.41s/it, train_loss=0.1656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/128 - Train Loss: 0.1656, Val Loss: 0.3354, Val Pearson: 0.6664\n",
      "Validation loss improved from 0.3364 to 0.3354. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/128: 100%|██████████| 15/15 [00:37<00:00,  2.50s/it, train_loss=0.1451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/128 - Train Loss: 0.1451, Val Loss: 0.3412, Val Pearson: 0.6618\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/128: 100%|██████████| 15/15 [00:36<00:00,  2.41s/it, train_loss=0.1349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/128 - Train Loss: 0.1349, Val Loss: 0.3427, Val Pearson: 0.6603\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/128: 100%|██████████| 15/15 [00:36<00:00,  2.42s/it, train_loss=0.1283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/128 - Train Loss: 0.1283, Val Loss: 0.3331, Val Pearson: 0.6651\n",
      "Validation loss improved from 0.3354 to 0.3331. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/128: 100%|██████████| 15/15 [00:36<00:00,  2.40s/it, train_loss=0.1265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/128 - Train Loss: 0.1265, Val Loss: 0.3496, Val Pearson: 0.6577\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/128: 100%|██████████| 15/15 [00:37<00:00,  2.48s/it, train_loss=0.1280]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/128 - Train Loss: 0.1280, Val Loss: 0.3427, Val Pearson: 0.6614\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/128: 100%|██████████| 15/15 [00:36<00:00,  2.41s/it, train_loss=0.1146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/128 - Train Loss: 0.1146, Val Loss: 0.3466, Val Pearson: 0.6623\n",
      "Validation loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/128: 100%|██████████| 15/15 [00:36<00:00,  2.44s/it, train_loss=0.0984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/128 - Train Loss: 0.0984, Val Loss: 0.3477, Val Pearson: 0.6585\n",
      "Validation loss did not improve for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/128: 100%|██████████| 15/15 [00:36<00:00,  2.43s/it, train_loss=0.0873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/128 - Train Loss: 0.0873, Val Loss: 0.3773, Val Pearson: 0.6421\n",
      "Validation loss did not improve for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/128: 100%|██████████| 15/15 [00:37<00:00,  2.48s/it, train_loss=0.0736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/128 - Train Loss: 0.0736, Val Loss: 0.3635, Val Pearson: 0.6510\n",
      "Validation loss did not improve for 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/128: 100%|██████████| 15/15 [00:36<00:00,  2.40s/it, train_loss=0.0707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/128 - Train Loss: 0.0707, Val Loss: 0.3683, Val Pearson: 0.6471\n",
      "Validation loss did not improve for 7 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/128: 100%|██████████| 15/15 [00:36<00:00,  2.45s/it, train_loss=0.0618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/128 - Train Loss: 0.0618, Val Loss: 0.3879, Val Pearson: 0.6327\n",
      "Validation loss did not improve for 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/128: 100%|██████████| 15/15 [00:37<00:00,  2.48s/it, train_loss=0.0549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/128 - Train Loss: 0.0549, Val Loss: 0.3663, Val Pearson: 0.6465\n",
      "Validation loss did not improve for 9 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/128: 100%|██████████| 15/15 [00:35<00:00,  2.37s/it, train_loss=0.0516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/128 - Train Loss: 0.0516, Val Loss: 0.3829, Val Pearson: 0.6403\n",
      "Validation loss did not improve for 10 epochs.\n",
      "Early stopping triggered at epoch 38. Loading best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-38649e80a240>:208: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3:\n",
      "  Validation Pearson Coefficient  acc: 0.6668947458267211\n",
      "  Validation Pearson Coefficient flat acc: 0.6650927818843155\n",
      "  Test acc: 0.7909515698750814\n",
      "  Test Pearson Coefficient acc(flattened): 0.8041059949908728\n",
      "Fold 4/4\n",
      "(900, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/128: 100%|██████████| 15/15 [00:34<00:00,  2.32s/it, train_loss=0.9675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128 - Train Loss: 0.9675, Val Loss: 0.8588, Val Pearson: 0.2659\n",
      "Validation loss improved from inf to 0.8588. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/128: 100%|██████████| 15/15 [00:35<00:00,  2.37s/it, train_loss=0.7091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/128 - Train Loss: 0.7091, Val Loss: 0.6727, Val Pearson: 0.3818\n",
      "Validation loss improved from 0.8588 to 0.6727. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/128: 100%|██████████| 15/15 [00:35<00:00,  2.39s/it, train_loss=0.5363]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/128 - Train Loss: 0.5363, Val Loss: 0.6341, Val Pearson: 0.4141\n",
      "Validation loss improved from 0.6727 to 0.6341. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/128: 100%|██████████| 15/15 [00:35<00:00,  2.39s/it, train_loss=0.4162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/128 - Train Loss: 0.4162, Val Loss: 0.5406, Val Pearson: 0.5075\n",
      "Validation loss improved from 0.6341 to 0.5406. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/128: 100%|██████████| 15/15 [00:35<00:00,  2.35s/it, train_loss=0.3520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/128 - Train Loss: 0.3520, Val Loss: 0.5273, Val Pearson: 0.5164\n",
      "Validation loss improved from 0.5406 to 0.5273. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/128: 100%|██████████| 15/15 [00:35<00:00,  2.39s/it, train_loss=0.3031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/128 - Train Loss: 0.3031, Val Loss: 0.4498, Val Pearson: 0.5769\n",
      "Validation loss improved from 0.5273 to 0.4498. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/128: 100%|██████████| 15/15 [00:35<00:00,  2.37s/it, train_loss=0.2726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/128 - Train Loss: 0.2726, Val Loss: 0.4319, Val Pearson: 0.6041\n",
      "Validation loss improved from 0.4498 to 0.4319. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/128: 100%|██████████| 15/15 [00:36<00:00,  2.44s/it, train_loss=0.2738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/128 - Train Loss: 0.2738, Val Loss: 0.4199, Val Pearson: 0.6159\n",
      "Validation loss improved from 0.4319 to 0.4199. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/128: 100%|██████████| 15/15 [00:36<00:00,  2.40s/it, train_loss=0.2493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/128 - Train Loss: 0.2493, Val Loss: 0.4152, Val Pearson: 0.6256\n",
      "Validation loss improved from 0.4199 to 0.4152. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/128: 100%|██████████| 15/15 [00:36<00:00,  2.42s/it, train_loss=0.2543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/128 - Train Loss: 0.2543, Val Loss: 0.4160, Val Pearson: 0.6242\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/128: 100%|██████████| 15/15 [00:36<00:00,  2.44s/it, train_loss=0.2315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/128 - Train Loss: 0.2315, Val Loss: 0.4006, Val Pearson: 0.6403\n",
      "Validation loss improved from 0.4152 to 0.4006. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/128: 100%|██████████| 15/15 [00:35<00:00,  2.39s/it, train_loss=0.2203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/128 - Train Loss: 0.2203, Val Loss: 0.3950, Val Pearson: 0.6450\n",
      "Validation loss improved from 0.4006 to 0.3950. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/128: 100%|██████████| 15/15 [00:35<00:00,  2.35s/it, train_loss=0.2086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/128 - Train Loss: 0.2086, Val Loss: 0.3828, Val Pearson: 0.6546\n",
      "Validation loss improved from 0.3950 to 0.3828. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/128: 100%|██████████| 15/15 [00:35<00:00,  2.35s/it, train_loss=0.2138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/128 - Train Loss: 0.2138, Val Loss: 0.3822, Val Pearson: 0.6506\n",
      "Validation loss improved from 0.3828 to 0.3822. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/128: 100%|██████████| 15/15 [00:36<00:00,  2.44s/it, train_loss=0.1954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/128 - Train Loss: 0.1954, Val Loss: 0.3806, Val Pearson: 0.6593\n",
      "Validation loss improved from 0.3822 to 0.3806. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/128: 100%|██████████| 15/15 [00:36<00:00,  2.42s/it, train_loss=0.1996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/128 - Train Loss: 0.1996, Val Loss: 0.3808, Val Pearson: 0.6603\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/128: 100%|██████████| 15/15 [00:36<00:00,  2.43s/it, train_loss=0.1992]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/128 - Train Loss: 0.1992, Val Loss: 0.3763, Val Pearson: 0.6625\n",
      "Validation loss improved from 0.3806 to 0.3763. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/128: 100%|██████████| 15/15 [00:36<00:00,  2.44s/it, train_loss=0.1822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/128 - Train Loss: 0.1822, Val Loss: 0.3845, Val Pearson: 0.6575\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/128: 100%|██████████| 15/15 [00:35<00:00,  2.39s/it, train_loss=0.1748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/128 - Train Loss: 0.1748, Val Loss: 0.3805, Val Pearson: 0.6609\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/128: 100%|██████████| 15/15 [00:35<00:00,  2.34s/it, train_loss=0.1695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/128 - Train Loss: 0.1695, Val Loss: 0.3999, Val Pearson: 0.6485\n",
      "Validation loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/128: 100%|██████████| 15/15 [00:35<00:00,  2.37s/it, train_loss=0.1524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/128 - Train Loss: 0.1524, Val Loss: 0.3797, Val Pearson: 0.6619\n",
      "Validation loss did not improve for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/128: 100%|██████████| 15/15 [00:36<00:00,  2.41s/it, train_loss=0.1395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/128 - Train Loss: 0.1395, Val Loss: 0.4204, Val Pearson: 0.6246\n",
      "Validation loss did not improve for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/128: 100%|██████████| 15/15 [00:35<00:00,  2.36s/it, train_loss=0.1589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/128 - Train Loss: 0.1589, Val Loss: 0.3991, Val Pearson: 0.6439\n",
      "Validation loss did not improve for 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/128: 100%|██████████| 15/15 [00:35<00:00,  2.40s/it, train_loss=0.1287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/128 - Train Loss: 0.1287, Val Loss: 0.3980, Val Pearson: 0.6455\n",
      "Validation loss did not improve for 7 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/128: 100%|██████████| 15/15 [00:35<00:00,  2.39s/it, train_loss=0.1109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/128 - Train Loss: 0.1109, Val Loss: 0.4080, Val Pearson: 0.6368\n",
      "Validation loss did not improve for 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/128: 100%|██████████| 15/15 [00:36<00:00,  2.40s/it, train_loss=0.0946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/128 - Train Loss: 0.0946, Val Loss: 0.4155, Val Pearson: 0.6314\n",
      "Validation loss did not improve for 9 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/128: 100%|██████████| 15/15 [00:35<00:00,  2.38s/it, train_loss=0.0880]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/128 - Train Loss: 0.0880, Val Loss: 0.4218, Val Pearson: 0.6279\n",
      "Validation loss did not improve for 10 epochs.\n",
      "Early stopping triggered at epoch 27. Loading best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-38649e80a240>:208: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n",
      "/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4:\n",
      "  Validation Pearson Coefficient  acc: 0.6237318634986877\n",
      "  Validation Pearson Coefficient flat acc: 0.6625138473549642\n",
      "  Test acc: 0.7788847287495931\n",
      "  Test Pearson Coefficient acc(flattened): 0.7945983461230314\n",
      "\n",
      "Training completed.\n",
      "Average metrics across all folds:\n",
      "  val_prc_acc: 0.6851448938250542\n",
      "  val_prc_acc_flat: 0.7015284605559333\n",
      "  test_acc: 0.7773389882511563\n",
      "  test_prc_flat: 0.7908176527486469\n",
      "  Fold: Average\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ls960-ft\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 128\n",
    "    batch_size = 64\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"VRBModel\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    \n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530ce6a-a07a-43de-9338-439b1c8213af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:61: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for 'microsoft/wavlm-large'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'microsoft/wavlm-large' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:59\u001b[0m, in \u001b[0;36mWav2Vec2Processor.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/processing_utils.py:944\u001b[0m, in \u001b[0;36mProcessorMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    942\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m token\n\u001b[0;32m--> 944\u001b[0m args \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_arguments_from_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    945\u001b[0m processor_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget_processor_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/processing_utils.py:990\u001b[0m, in \u001b[0;36mProcessorMixin._get_arguments_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    988\u001b[0m         attribute_class \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(transformers_module, class_name)\n\u001b[0;32m--> 990\u001b[0m     args\u001b[39m.\u001b[39mappend(attribute_class\u001b[39m.\u001b[39;49mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    991\u001b[0m \u001b[39mreturn\u001b[39;00m args\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:920\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    918\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTokenizer class \u001b[39m\u001b[39m{\u001b[39;00mtokenizer_class_candidate\u001b[39m}\u001b[39;00m\u001b[39m does not exist or is not currently imported.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    919\u001b[0m         )\n\u001b[0;32m--> 920\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer_class\u001b[39m.\u001b[39;49mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    922\u001b[0m \u001b[39m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[1;32m    923\u001b[0m \u001b[39m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2197\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2196\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(full_file_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m full_file_name \u001b[39min\u001b[39;00m resolved_vocab_files\u001b[39m.\u001b[39mvalues()) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m gguf_file:\n\u001b[0;32m-> 2197\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2198\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load tokenizer for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. If you were trying to load it from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2199\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, make sure you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have a local directory with the same name. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2200\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOtherwise, make sure \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is the correct path to a directory \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2201\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcontaining all relevant files for a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m tokenizer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2202\u001b[0m     )\n\u001b[1;32m   2204\u001b[0m \u001b[39mfor\u001b[39;00m file_id, file_path \u001b[39min\u001b[39;00m vocab_files\u001b[39m.\u001b[39mitems():\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'microsoft/wavlm-large'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'microsoft/wavlm-large' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:337\u001b[0m\n\u001b[1;32m    333\u001b[0m config \u001b[39m=\u001b[39m model_config[\u001b[39m\"\u001b[39m\u001b[39mRespBertCNNModelV2\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    336\u001b[0m \u001b[39m## same wav2vec2 base model and pipeline used in the paper\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m processor \u001b[39m=\u001b[39m AutoProcessor\u001b[39m.\u001b[39;49mfrom_pretrained(config[\u001b[39m\"\u001b[39;49m\u001b[39mmodel_name\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    339\u001b[0m train(\n\u001b[1;32m    340\u001b[0m     path_to_data\u001b[39m=\u001b[39mpath\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mComParE2020_Breathing/wav/\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    341\u001b[0m     path_to_labels\u001b[39m=\u001b[39mpath\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mComParE2020_Breathing/lab/\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m     processor \u001b[39m=\u001b[39m processor\n\u001b[1;32m    350\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/auto/processing_auto.py:333\u001b[0m, in \u001b[0;36mAutoProcessor.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39m# Last try: we use the PROCESSOR_MAPPING.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m PROCESSOR_MAPPING:\n\u001b[0;32m--> 333\u001b[0m     \u001b[39mreturn\u001b[39;00m PROCESSOR_MAPPING[\u001b[39mtype\u001b[39;49m(config)]\u001b[39m.\u001b[39;49mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    335\u001b[0m \u001b[39m# At this stage, there doesn't seem to be a `Processor` class available for this model, so let's try a\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[39m# tokenizer.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:71\u001b[0m, in \u001b[0;36mWav2Vec2Processor.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m     62\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoading a tokenizer inside \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m from a config that does not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     63\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m include a `tokenizer_class` attribute is deprecated and will be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m     68\u001b[0m )\n\u001b[1;32m     70\u001b[0m feature_extractor \u001b[39m=\u001b[39m Wav2Vec2FeatureExtractor\u001b[39m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 71\u001b[0m tokenizer \u001b[39m=\u001b[39m Wav2Vec2CTCTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     73\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(feature_extractor\u001b[39m=\u001b[39mfeature_extractor, tokenizer\u001b[39m=\u001b[39mtokenizer)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2197\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2194\u001b[0m \u001b[39m# If one passes a GGUF file path to `gguf_file` there is no need for this check as the tokenizer will be\u001b[39;00m\n\u001b[1;32m   2195\u001b[0m \u001b[39m# loaded directly from the GGUF file.\u001b[39;00m\n\u001b[1;32m   2196\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(full_file_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m full_file_name \u001b[39min\u001b[39;00m resolved_vocab_files\u001b[39m.\u001b[39mvalues()) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m gguf_file:\n\u001b[0;32m-> 2197\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2198\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load tokenizer for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. If you were trying to load it from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2199\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, make sure you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have a local directory with the same name. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2200\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOtherwise, make sure \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is the correct path to a directory \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2201\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcontaining all relevant files for a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m tokenizer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2202\u001b[0m     )\n\u001b[1;32m   2204\u001b[0m \u001b[39mfor\u001b[39;00m file_id, file_path \u001b[39min\u001b[39;00m vocab_files\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   2205\u001b[0m     \u001b[39mif\u001b[39;00m file_id \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'microsoft/wavlm-large'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'microsoft/wavlm-large' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ls960-ft\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "            \"RespBertCNNModelV2\": {\n",
    "            'model' : RespBertCNNModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 60\n",
    "    batch_size = 25\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertCNNModelV2\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    \n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be75d357-e4bd-4203-8ca0-b57e282f70ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   0%|          | 0/35 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60:   0%|          | 0/35 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacity of 93.12 GiB of which 2.34 GiB is free. Including non-PyTorch memory, this process has 90.77 GiB memory in use. Of the allocated memory 89.21 GiB is allocated by PyTorch, and 912.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:340\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39m## same wav2vec2 base model and pipeline used in the paper\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39m#processor = AutoProcessor.from_pretrained(config[\"model_name\"])\u001b[39;00m\n\u001b[1;32m    338\u001b[0m processor \u001b[39m=\u001b[39m Wav2Vec2FeatureExtractor\u001b[39m.\u001b[39mfrom_pretrained(config[\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 340\u001b[0m train(\n\u001b[1;32m    341\u001b[0m     path_to_data\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/wav/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    342\u001b[0m     path_to_labels\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/lab/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    343\u001b[0m     window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    344\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    345\u001b[0m     config \u001b[39m=\u001b[39;49m config,\n\u001b[1;32m    346\u001b[0m     step_size\u001b[39m=\u001b[39;49mstep_size,\n\u001b[1;32m    347\u001b[0m     data_parts\u001b[39m=\u001b[39;49m data_parts ,\n\u001b[1;32m    348\u001b[0m     early_stopping_patience\u001b[39m=\u001b[39;49m early_stopping_patience,\n\u001b[1;32m    349\u001b[0m     epochs\u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    350\u001b[0m     processor \u001b[39m=\u001b[39;49m processor\n\u001b[1;32m    351\u001b[0m )\n",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:146\u001b[0m\n\u001b[1;32m    144\u001b[0m input_values \u001b[39m=\u001b[39m batch_d\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    145\u001b[0m batch_lbs \u001b[39m=\u001b[39m batch_lbs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 146\u001b[0m outputs \u001b[39m=\u001b[39m model(input_values)\n\u001b[1;32m    147\u001b[0m loss \u001b[39m=\u001b[39m correlation_coefficient_loss(outputs, batch_lbs)\n\u001b[1;32m    148\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/home3/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_models.py:686\u001b[0m, in \u001b[0;36mRespBertCNNModelV2.forward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_values):\n\u001b[0;32m--> 686\u001b[0m     x\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwav_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minput_values)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    689\u001b[0m     \u001b[39m#x = self.transformer_layer(x)        \u001b[39;00m\n\u001b[1;32m    690\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)       \n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:1228\u001b[0m, in \u001b[0;36mWavLMModel.forward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1223\u001b[0m hidden_states, extract_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_projection(extract_features)\n\u001b[1;32m   1224\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mask_hidden_states(\n\u001b[1;32m   1225\u001b[0m     hidden_states, mask_time_indices\u001b[39m=\u001b[39mmask_time_indices, attention_mask\u001b[39m=\u001b[39mattention_mask\n\u001b[1;32m   1226\u001b[0m )\n\u001b[0;32m-> 1228\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1229\u001b[0m     hidden_states,\n\u001b[1;32m   1230\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1231\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1232\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1233\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1234\u001b[0m )\n\u001b[1;32m   1236\u001b[0m hidden_states \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madapter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:808\u001b[0m, in \u001b[0;36mWavLMEncoderStableLayerNorm.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    800\u001b[0m         layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    801\u001b[0m             layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    802\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    805\u001b[0m             output_attentions,\n\u001b[1;32m    806\u001b[0m         )\n\u001b[1;32m    807\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 808\u001b[0m         layer_outputs \u001b[39m=\u001b[39m layer(\n\u001b[1;32m    809\u001b[0m             hidden_states,\n\u001b[1;32m    810\u001b[0m             attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    811\u001b[0m             output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    812\u001b[0m             position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    813\u001b[0m         )\n\u001b[1;32m    814\u001b[0m     hidden_states, position_bias \u001b[39m=\u001b[39m layer_outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    816\u001b[0m \u001b[39mif\u001b[39;00m skip_the_layer:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:651\u001b[0m, in \u001b[0;36mWavLMEncoderLayerStableLayerNorm.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, output_attentions)\u001b[0m\n\u001b[1;32m    649\u001b[0m attn_residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m    650\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 651\u001b[0m hidden_states, attn_weights, position_bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    652\u001b[0m     hidden_states,\n\u001b[1;32m    653\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    654\u001b[0m     position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    655\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    656\u001b[0m )\n\u001b[1;32m    657\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    658\u001b[0m hidden_states \u001b[39m=\u001b[39m attn_residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:474\u001b[0m, in \u001b[0;36mWavLMAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, output_attentions, index)\u001b[0m\n\u001b[1;32m    471\u001b[0m gated_position_bias \u001b[39m=\u001b[39m gate_output\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m position_bias\n\u001b[1;32m    472\u001b[0m gated_position_bias \u001b[39m=\u001b[39m gated_position_bias\u001b[39m.\u001b[39mview((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, tgt_len, tgt_len))\n\u001b[0;32m--> 474\u001b[0m attn_output, attn_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtorch_multi_head_self_attention(\n\u001b[1;32m    475\u001b[0m     hidden_states, attention_mask, gated_position_bias, output_attentions\n\u001b[1;32m    476\u001b[0m )\n\u001b[1;32m    478\u001b[0m \u001b[39mreturn\u001b[39;00m attn_output, attn_weights, position_bias\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:498\u001b[0m, in \u001b[0;36mWavLMAttention.torch_multi_head_self_attention\u001b[0;34m(self, hidden_states, attention_mask, gated_position_bias, output_attentions)\u001b[0m\n\u001b[1;32m    494\u001b[0m add_zero_attn \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[39m# PyTorch 1.3.0 has F.multi_head_attention_forward defined\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[39m# so no problem with backwards compatibility\u001b[39;00m\n\u001b[0;32m--> 498\u001b[0m attn_output, attn_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m    499\u001b[0m     query,\n\u001b[1;32m    500\u001b[0m     key,\n\u001b[1;32m    501\u001b[0m     value,\n\u001b[1;32m    502\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim,\n\u001b[1;32m    503\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m    504\u001b[0m     torch\u001b[39m.\u001b[39;49mempty([\u001b[39m0\u001b[39;49m]),\n\u001b[1;32m    505\u001b[0m     torch\u001b[39m.\u001b[39;49mcat((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_proj\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk_proj\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_proj\u001b[39m.\u001b[39;49mbias)),\n\u001b[1;32m    506\u001b[0m     bias_k,\n\u001b[1;32m    507\u001b[0m     bias_v,\n\u001b[1;32m    508\u001b[0m     add_zero_attn,\n\u001b[1;32m    509\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout,\n\u001b[1;32m    510\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    511\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    512\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m    513\u001b[0m     key_padding_mask,\n\u001b[1;32m    514\u001b[0m     output_attentions,\n\u001b[1;32m    515\u001b[0m     gated_position_bias,\n\u001b[1;32m    516\u001b[0m     use_separate_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    517\u001b[0m     q_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    518\u001b[0m     k_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    519\u001b[0m     v_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    520\u001b[0m )\n\u001b[1;32m    522\u001b[0m \u001b[39m# [Seq_Len, Batch Size, ...] -> [Batch Size, Seq_Len, ...]\u001b[39;00m\n\u001b[1;32m    523\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5560\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5557\u001b[0m k \u001b[39m=\u001b[39m k\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m   5558\u001b[0m v \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 5560\u001b[0m attn_output \u001b[39m=\u001b[39m scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n\u001b[1;32m   5561\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m   5563\u001b[0m attn_output \u001b[39m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacity of 93.12 GiB of which 2.34 GiB is free. Including non-PyTorch memory, this process has 90.77 GiB memory in use. Of the allocated memory 89.21 GiB is allocated by PyTorch, and 912.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ls960-ft\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "            \"RespBertCNNModelV2\": {\n",
    "            'model' : RespBertCNNModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 60\n",
    "    batch_size = 25\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertCNNModelV2\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    #processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c4eb17-978a-4820-a37b-fb9ec6da2bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   0%|          | 0/58 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.75 GiB. GPU 0 has a total capacity of 93.12 GiB of which 1.41 GiB is free. Including non-PyTorch memory, this process has 91.70 GiB memory in use. Of the allocated memory 90.99 GiB is allocated by PyTorch, and 40.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:340\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39m## same wav2vec2 base model and pipeline used in the paper\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39m#processor = AutoProcessor.from_pretrained(config[\"model_name\"])\u001b[39;00m\n\u001b[1;32m    338\u001b[0m processor \u001b[39m=\u001b[39m Wav2Vec2FeatureExtractor\u001b[39m.\u001b[39mfrom_pretrained(config[\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 340\u001b[0m train(\n\u001b[1;32m    341\u001b[0m     path_to_data\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/wav/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    342\u001b[0m     path_to_labels\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/lab/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    343\u001b[0m     window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    344\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    345\u001b[0m     config \u001b[39m=\u001b[39;49m config,\n\u001b[1;32m    346\u001b[0m     step_size\u001b[39m=\u001b[39;49mstep_size,\n\u001b[1;32m    347\u001b[0m     data_parts\u001b[39m=\u001b[39;49m data_parts ,\n\u001b[1;32m    348\u001b[0m     early_stopping_patience\u001b[39m=\u001b[39;49m early_stopping_patience,\n\u001b[1;32m    349\u001b[0m     epochs\u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    350\u001b[0m     processor \u001b[39m=\u001b[39;49m processor\n\u001b[1;32m    351\u001b[0m )\n",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:146\u001b[0m\n\u001b[1;32m    144\u001b[0m input_values \u001b[39m=\u001b[39m batch_d\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    145\u001b[0m batch_lbs \u001b[39m=\u001b[39m batch_lbs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 146\u001b[0m outputs \u001b[39m=\u001b[39m model(input_values)\n\u001b[1;32m    147\u001b[0m loss \u001b[39m=\u001b[39m correlation_coefficient_loss(outputs, batch_lbs)\n\u001b[1;32m    148\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/home3/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_models.py:686\u001b[0m, in \u001b[0;36mRespBertCNNModelV2.forward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_values):\n\u001b[0;32m--> 686\u001b[0m     x\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwav_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minput_values)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    689\u001b[0m     \u001b[39m#x = self.transformer_layer(x)        \u001b[39;00m\n\u001b[1;32m    690\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)       \n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:1214\u001b[0m, in \u001b[0;36mWavLMModel.forward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1209\u001b[0m output_hidden_states \u001b[39m=\u001b[39m (\n\u001b[1;32m   1210\u001b[0m     output_hidden_states \u001b[39mif\u001b[39;00m output_hidden_states \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39moutput_hidden_states\n\u001b[1;32m   1211\u001b[0m )\n\u001b[1;32m   1212\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1214\u001b[0m extract_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_extractor(input_values)\n\u001b[1;32m   1215\u001b[0m extract_features \u001b[39m=\u001b[39m extract_features\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m   1217\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m     \u001b[39m# compute reduced attention_mask corresponding to feature vectors\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:368\u001b[0m, in \u001b[0;36mWavLMFeatureEncoder.forward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    363\u001b[0m         hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    364\u001b[0m             conv_layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    365\u001b[0m             hidden_states,\n\u001b[1;32m    366\u001b[0m         )\n\u001b[1;32m    367\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m         hidden_states \u001b[39m=\u001b[39m conv_layer(hidden_states)\n\u001b[1;32m    370\u001b[0m \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:235\u001b[0m, in \u001b[0;36mWavLMLayerNormConvLayer.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states):\n\u001b[0;32m--> 235\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(hidden_states)\n\u001b[1;32m    237\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39mtranspose(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    238\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/conv.py:308\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 308\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/conv.py:304\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    302\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    303\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 304\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    305\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.75 GiB. GPU 0 has a total capacity of 93.12 GiB of which 1.41 GiB is free. Including non-PyTorch memory, this process has 91.70 GiB memory in use. Of the allocated memory 90.99 GiB is allocated by PyTorch, and 40.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ls960-ft\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "            \"RespBertCNNModelV2\": {\n",
    "            'model' : RespBertCNNModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 60\n",
    "    batch_size = 15\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertCNNModelV2\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    #processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d81ce-8ef1-4575-a259-5a90c2f34605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   0%|          | 0/58 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60:   0%|          | 0/58 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacity of 93.12 GiB of which 314.75 MiB is free. Including non-PyTorch memory, this process has 92.80 GiB memory in use. Of the allocated memory 91.90 GiB is allocated by PyTorch, and 245.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:340\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39m## same wav2vec2 base model and pipeline used in the paper\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39m#processor = AutoProcessor.from_pretrained(config[\"model_name\"])\u001b[39;00m\n\u001b[1;32m    338\u001b[0m processor \u001b[39m=\u001b[39m Wav2Vec2FeatureExtractor\u001b[39m.\u001b[39mfrom_pretrained(config[\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 340\u001b[0m train(\n\u001b[1;32m    341\u001b[0m     path_to_data\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/wav/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    342\u001b[0m     path_to_labels\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/lab/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    343\u001b[0m     window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    344\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    345\u001b[0m     config \u001b[39m=\u001b[39;49m config,\n\u001b[1;32m    346\u001b[0m     step_size\u001b[39m=\u001b[39;49mstep_size,\n\u001b[1;32m    347\u001b[0m     data_parts\u001b[39m=\u001b[39;49m data_parts ,\n\u001b[1;32m    348\u001b[0m     early_stopping_patience\u001b[39m=\u001b[39;49m early_stopping_patience,\n\u001b[1;32m    349\u001b[0m     epochs\u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    350\u001b[0m     processor \u001b[39m=\u001b[39;49m processor\n\u001b[1;32m    351\u001b[0m )\n",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:146\u001b[0m\n\u001b[1;32m    144\u001b[0m input_values \u001b[39m=\u001b[39m batch_d\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    145\u001b[0m batch_lbs \u001b[39m=\u001b[39m batch_lbs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 146\u001b[0m outputs \u001b[39m=\u001b[39m model(input_values)\n\u001b[1;32m    147\u001b[0m loss \u001b[39m=\u001b[39m correlation_coefficient_loss(outputs, batch_lbs)\n\u001b[1;32m    148\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/home3/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_models.py:686\u001b[0m, in \u001b[0;36mRespBertCNNModelV2.forward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_values):\n\u001b[0;32m--> 686\u001b[0m     x\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwav_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minput_values)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    689\u001b[0m     \u001b[39m#x = self.transformer_layer(x)        \u001b[39;00m\n\u001b[1;32m    690\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)       \n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:1228\u001b[0m, in \u001b[0;36mWavLMModel.forward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1223\u001b[0m hidden_states, extract_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_projection(extract_features)\n\u001b[1;32m   1224\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mask_hidden_states(\n\u001b[1;32m   1225\u001b[0m     hidden_states, mask_time_indices\u001b[39m=\u001b[39mmask_time_indices, attention_mask\u001b[39m=\u001b[39mattention_mask\n\u001b[1;32m   1226\u001b[0m )\n\u001b[0;32m-> 1228\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1229\u001b[0m     hidden_states,\n\u001b[1;32m   1230\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1231\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1232\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1233\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1234\u001b[0m )\n\u001b[1;32m   1236\u001b[0m hidden_states \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madapter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:808\u001b[0m, in \u001b[0;36mWavLMEncoderStableLayerNorm.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    800\u001b[0m         layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    801\u001b[0m             layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    802\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    805\u001b[0m             output_attentions,\n\u001b[1;32m    806\u001b[0m         )\n\u001b[1;32m    807\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 808\u001b[0m         layer_outputs \u001b[39m=\u001b[39m layer(\n\u001b[1;32m    809\u001b[0m             hidden_states,\n\u001b[1;32m    810\u001b[0m             attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    811\u001b[0m             output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    812\u001b[0m             position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    813\u001b[0m         )\n\u001b[1;32m    814\u001b[0m     hidden_states, position_bias \u001b[39m=\u001b[39m layer_outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    816\u001b[0m \u001b[39mif\u001b[39;00m skip_the_layer:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:651\u001b[0m, in \u001b[0;36mWavLMEncoderLayerStableLayerNorm.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, output_attentions)\u001b[0m\n\u001b[1;32m    649\u001b[0m attn_residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m    650\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 651\u001b[0m hidden_states, attn_weights, position_bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    652\u001b[0m     hidden_states,\n\u001b[1;32m    653\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    654\u001b[0m     position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    655\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    656\u001b[0m )\n\u001b[1;32m    657\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    658\u001b[0m hidden_states \u001b[39m=\u001b[39m attn_residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:474\u001b[0m, in \u001b[0;36mWavLMAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, output_attentions, index)\u001b[0m\n\u001b[1;32m    471\u001b[0m gated_position_bias \u001b[39m=\u001b[39m gate_output\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m position_bias\n\u001b[1;32m    472\u001b[0m gated_position_bias \u001b[39m=\u001b[39m gated_position_bias\u001b[39m.\u001b[39mview((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, tgt_len, tgt_len))\n\u001b[0;32m--> 474\u001b[0m attn_output, attn_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtorch_multi_head_self_attention(\n\u001b[1;32m    475\u001b[0m     hidden_states, attention_mask, gated_position_bias, output_attentions\n\u001b[1;32m    476\u001b[0m )\n\u001b[1;32m    478\u001b[0m \u001b[39mreturn\u001b[39;00m attn_output, attn_weights, position_bias\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:498\u001b[0m, in \u001b[0;36mWavLMAttention.torch_multi_head_self_attention\u001b[0;34m(self, hidden_states, attention_mask, gated_position_bias, output_attentions)\u001b[0m\n\u001b[1;32m    494\u001b[0m add_zero_attn \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[39m# PyTorch 1.3.0 has F.multi_head_attention_forward defined\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[39m# so no problem with backwards compatibility\u001b[39;00m\n\u001b[0;32m--> 498\u001b[0m attn_output, attn_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m    499\u001b[0m     query,\n\u001b[1;32m    500\u001b[0m     key,\n\u001b[1;32m    501\u001b[0m     value,\n\u001b[1;32m    502\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim,\n\u001b[1;32m    503\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m    504\u001b[0m     torch\u001b[39m.\u001b[39;49mempty([\u001b[39m0\u001b[39;49m]),\n\u001b[1;32m    505\u001b[0m     torch\u001b[39m.\u001b[39;49mcat((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_proj\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk_proj\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_proj\u001b[39m.\u001b[39;49mbias)),\n\u001b[1;32m    506\u001b[0m     bias_k,\n\u001b[1;32m    507\u001b[0m     bias_v,\n\u001b[1;32m    508\u001b[0m     add_zero_attn,\n\u001b[1;32m    509\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout,\n\u001b[1;32m    510\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    511\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    512\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m    513\u001b[0m     key_padding_mask,\n\u001b[1;32m    514\u001b[0m     output_attentions,\n\u001b[1;32m    515\u001b[0m     gated_position_bias,\n\u001b[1;32m    516\u001b[0m     use_separate_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    517\u001b[0m     q_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    518\u001b[0m     k_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    519\u001b[0m     v_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    520\u001b[0m )\n\u001b[1;32m    522\u001b[0m \u001b[39m# [Seq_Len, Batch Size, ...] -> [Batch Size, Seq_Len, ...]\u001b[39;00m\n\u001b[1;32m    523\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5560\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5557\u001b[0m k \u001b[39m=\u001b[39m k\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m   5558\u001b[0m v \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 5560\u001b[0m attn_output \u001b[39m=\u001b[39m scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n\u001b[1;32m   5561\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m   5563\u001b[0m attn_output \u001b[39m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacity of 93.12 GiB of which 314.75 MiB is free. Including non-PyTorch memory, this process has 92.80 GiB memory in use. Of the allocated memory 91.90 GiB is allocated by PyTorch, and 245.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ls960-ft\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "            \"RespBertCNNModelV2\": {\n",
    "            'model' : RespBertCNNModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 60\n",
    "    batch_size = 15\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertCNNModelV2\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    #processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b0f37f-9e65-4f8b-a567-f61d1fe7c956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   0%|          | 0/67 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60: 100%|██████████| 67/67 [02:09<00:00,  1.93s/it, train_loss=0.8820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60 - Train Loss: 0.8820, Val Loss: 0.9271, Val Pearson: 0.1845\n",
      "Validation loss improved from inf to 0.9271. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/60: 100%|██████████| 67/67 [02:09<00:00,  1.93s/it, train_loss=0.4037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/60 - Train Loss: 0.4037, Val Loss: 0.4840, Val Pearson: 0.7195\n",
      "Validation loss improved from 0.9271 to 0.4840. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/60: 100%|██████████| 67/67 [02:09<00:00,  1.94s/it, train_loss=0.2746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/60 - Train Loss: 0.2746, Val Loss: 0.1686, Val Pearson: 0.8376\n",
      "Validation loss improved from 0.4840 to 0.1686. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/60: 100%|██████████| 67/67 [02:09<00:00,  1.94s/it, train_loss=0.2206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/60 - Train Loss: 0.2206, Val Loss: 0.2022, Val Pearson: 0.8093\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/60: 100%|██████████| 67/67 [02:08<00:00,  1.92s/it, train_loss=0.1811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/60 - Train Loss: 0.1811, Val Loss: 0.1725, Val Pearson: 0.8296\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/60: 100%|██████████| 67/67 [02:09<00:00,  1.93s/it, train_loss=0.1428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/60 - Train Loss: 0.1428, Val Loss: 0.1616, Val Pearson: 0.8407\n",
      "Validation loss improved from 0.1686 to 0.1616. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/60: 100%|██████████| 67/67 [02:08<00:00,  1.92s/it, train_loss=0.1143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/60 - Train Loss: 0.1143, Val Loss: 0.1737, Val Pearson: 0.8324\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/60: 100%|██████████| 67/67 [02:10<00:00,  1.94s/it, train_loss=0.0871]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/60 - Train Loss: 0.0871, Val Loss: 0.1736, Val Pearson: 0.8300\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/60: 100%|██████████| 67/67 [02:10<00:00,  1.94s/it, train_loss=0.0820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/60 - Train Loss: 0.0820, Val Loss: 0.1770, Val Pearson: 0.8332\n",
      "Validation loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/60: 100%|██████████| 67/67 [02:10<00:00,  1.95s/it, train_loss=0.0649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/60 - Train Loss: 0.0649, Val Loss: 0.1662, Val Pearson: 0.8398\n",
      "Validation loss did not improve for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/60: 100%|██████████| 67/67 [02:09<00:00,  1.94s/it, train_loss=0.0542]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/60 - Train Loss: 0.0542, Val Loss: 0.1617, Val Pearson: 0.8414\n",
      "Validation loss did not improve for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/60: 100%|██████████| 67/67 [02:09<00:00,  1.94s/it, train_loss=0.0545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/60 - Train Loss: 0.0545, Val Loss: 0.1612, Val Pearson: 0.8467\n",
      "Validation loss improved from 0.1616 to 0.1612. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/60: 100%|██████████| 67/67 [02:09<00:00,  1.93s/it, train_loss=0.0475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/60 - Train Loss: 0.0475, Val Loss: 0.1871, Val Pearson: 0.8310\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/60: 100%|██████████| 67/67 [02:07<00:00,  1.91s/it, train_loss=0.0419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/60 - Train Loss: 0.0419, Val Loss: 0.1576, Val Pearson: 0.8476\n",
      "Validation loss improved from 0.1612 to 0.1576. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/60: 100%|██████████| 67/67 [02:08<00:00,  1.92s/it, train_loss=0.0373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/60 - Train Loss: 0.0373, Val Loss: 0.1612, Val Pearson: 0.8468\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/60: 100%|██████████| 67/67 [02:09<00:00,  1.93s/it, train_loss=0.0367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/60 - Train Loss: 0.0367, Val Loss: 0.1599, Val Pearson: 0.8438\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/60: 100%|██████████| 67/67 [02:10<00:00,  1.94s/it, train_loss=0.0360]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/60 - Train Loss: 0.0360, Val Loss: 0.1682, Val Pearson: 0.8373\n",
      "Validation loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/60: 100%|██████████| 67/67 [02:10<00:00,  1.94s/it, train_loss=0.0317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/60 - Train Loss: 0.0317, Val Loss: 0.1696, Val Pearson: 0.8399\n",
      "Validation loss did not improve for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/60: 100%|██████████| 67/67 [02:09<00:00,  1.93s/it, train_loss=0.0289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/60 - Train Loss: 0.0289, Val Loss: 0.1642, Val Pearson: 0.8417\n",
      "Validation loss did not improve for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/60: 100%|██████████| 67/67 [02:09<00:00,  1.93s/it, train_loss=0.0267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/60 - Train Loss: 0.0267, Val Loss: 0.1847, Val Pearson: 0.8306\n",
      "Validation loss did not improve for 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/60: 100%|██████████| 67/67 [02:09<00:00,  1.94s/it, train_loss=0.0247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/60 - Train Loss: 0.0247, Val Loss: 0.1638, Val Pearson: 0.8401\n",
      "Validation loss did not improve for 7 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/60: 100%|██████████| 67/67 [02:09<00:00,  1.94s/it, train_loss=0.0225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/60 - Train Loss: 0.0225, Val Loss: 0.1605, Val Pearson: 0.8456\n",
      "Validation loss did not improve for 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/60: 100%|██████████| 67/67 [02:08<00:00,  1.92s/it, train_loss=0.0209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/60 - Train Loss: 0.0209, Val Loss: 0.1577, Val Pearson: 0.8450\n",
      "Validation loss did not improve for 9 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/60: 100%|██████████| 67/67 [02:09<00:00,  1.94s/it, train_loss=0.0195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/60 - Train Loss: 0.0195, Val Loss: 0.1649, Val Pearson: 0.8422\n",
      "Validation loss did not improve for 10 epochs.\n",
      "Early stopping triggered at epoch 24. Loading best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f68d9b0fa455>:208: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Validation Pearson Coefficient  acc: 0.8423852348327636\n",
      "  Validation Pearson Coefficient flat acc: 0.8475608024030405\n",
      "  Test acc: 0.7859138780170016\n",
      "  Test Pearson Coefficient acc(flattened): 0.8007289066878426\n",
      "Fold 2/4\n",
      "(900, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   0%|          | 0/70 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60: 100%|██████████| 70/70 [02:13<00:00,  1.90s/it, train_loss=0.7956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60 - Train Loss: 0.7956, Val Loss: 0.6812, Val Pearson: 0.4716\n",
      "Validation loss improved from inf to 0.6812. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/60: 100%|██████████| 70/70 [02:13<00:00,  1.91s/it, train_loss=0.2667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/60 - Train Loss: 0.2667, Val Loss: 0.2774, Val Pearson: 0.7448\n",
      "Validation loss improved from 0.6812 to 0.2774. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/60: 100%|██████████| 70/70 [02:12<00:00,  1.89s/it, train_loss=0.1832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/60 - Train Loss: 0.1832, Val Loss: 0.2921, Val Pearson: 0.7379\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/60: 100%|██████████| 70/70 [02:14<00:00,  1.91s/it, train_loss=0.1404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/60 - Train Loss: 0.1404, Val Loss: 0.2514, Val Pearson: 0.7631\n",
      "Validation loss improved from 0.2774 to 0.2514. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/60: 100%|██████████| 70/70 [02:14<00:00,  1.92s/it, train_loss=0.1093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/60 - Train Loss: 0.1093, Val Loss: 0.2481, Val Pearson: 0.7648\n",
      "Validation loss improved from 0.2514 to 0.2481. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/60: 100%|██████████| 70/70 [02:14<00:00,  1.92s/it, train_loss=0.0849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/60 - Train Loss: 0.0849, Val Loss: 0.2498, Val Pearson: 0.7626\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/60: 100%|██████████| 70/70 [02:13<00:00,  1.91s/it, train_loss=0.0694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/60 - Train Loss: 0.0694, Val Loss: 0.2540, Val Pearson: 0.7609\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/60: 100%|██████████| 70/70 [02:14<00:00,  1.91s/it, train_loss=0.0632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/60 - Train Loss: 0.0632, Val Loss: 0.2542, Val Pearson: 0.7544\n",
      "Validation loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/60: 100%|██████████| 70/70 [02:14<00:00,  1.91s/it, train_loss=0.0512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/60 - Train Loss: 0.0512, Val Loss: 0.2548, Val Pearson: 0.7558\n",
      "Validation loss did not improve for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/60: 100%|██████████| 70/70 [02:14<00:00,  1.92s/it, train_loss=0.0471]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ls960-ft\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "            \"RespBertCNNModelV2\": {\n",
    "            'model' : RespBertCNNModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 60\n",
    "    batch_size = 13\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertCNNModelV2\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    #processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ddfde3-5e75-44bb-b9e8-cd83367bf704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   0%|          | 0/67 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60: 100%|██████████| 67/67 [02:09<00:00,  1.94s/it, train_loss=0.8485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60 - Train Loss: 0.8485, Val Loss: 0.5918, Val Pearson: 0.4822\n",
      "Validation loss improved from inf to 0.5918. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/60: 100%|██████████| 67/67 [02:08<00:00,  1.91s/it, train_loss=0.4059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/60 - Train Loss: 0.4059, Val Loss: 0.2168, Val Pearson: 0.7915\n",
      "Validation loss improved from 0.5918 to 0.2168. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/60: 100%|██████████| 67/67 [02:08<00:00,  1.91s/it, train_loss=0.2648]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/60 - Train Loss: 0.2648, Val Loss: 0.1711, Val Pearson: 0.8308\n",
      "Validation loss improved from 0.2168 to 0.1711. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/60: 100%|██████████| 67/67 [02:08<00:00,  1.92s/it, train_loss=0.2053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/60 - Train Loss: 0.2053, Val Loss: 0.1694, Val Pearson: 0.8359\n",
      "Validation loss improved from 0.1711 to 0.1694. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/60: 100%|██████████| 67/67 [02:09<00:00,  1.93s/it, train_loss=0.1643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/60 - Train Loss: 0.1643, Val Loss: 0.1751, Val Pearson: 0.8335\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/60: 100%|██████████| 67/67 [02:08<00:00,  1.92s/it, train_loss=0.1326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/60 - Train Loss: 0.1326, Val Loss: 0.1593, Val Pearson: 0.8444\n",
      "Validation loss improved from 0.1694 to 0.1593. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/60: 100%|██████████| 67/67 [02:09<00:00,  1.93s/it, train_loss=0.1051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/60 - Train Loss: 0.1051, Val Loss: 0.1749, Val Pearson: 0.8363\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/60: 100%|██████████| 67/67 [02:09<00:00,  1.94s/it, train_loss=0.0845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/60 - Train Loss: 0.0845, Val Loss: 0.1877, Val Pearson: 0.8277\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/60: 100%|██████████| 67/67 [02:08<00:00,  1.92s/it, train_loss=0.0748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/60 - Train Loss: 0.0748, Val Loss: 0.1616, Val Pearson: 0.8450\n",
      "Validation loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/60: 100%|██████████| 67/67 [02:09<00:00,  1.93s/it, train_loss=0.0654]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/60 - Train Loss: 0.0654, Val Loss: 0.1627, Val Pearson: 0.8419\n",
      "Validation loss did not improve for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/60: 100%|██████████| 67/67 [02:08<00:00,  1.91s/it, train_loss=0.0541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/60 - Train Loss: 0.0541, Val Loss: 0.1660, Val Pearson: 0.8431\n",
      "Validation loss did not improve for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/60: 100%|██████████| 67/67 [02:09<00:00,  1.93s/it, train_loss=0.0452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/60 - Train Loss: 0.0452, Val Loss: 0.1659, Val Pearson: 0.8454\n",
      "Validation loss did not improve for 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/60: 100%|██████████| 67/67 [02:09<00:00,  1.93s/it, train_loss=0.0380]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/60 - Train Loss: 0.0380, Val Loss: 0.1691, Val Pearson: 0.8399\n",
      "Validation loss did not improve for 7 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/60: 100%|██████████| 67/67 [02:09<00:00,  1.93s/it, train_loss=0.0332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/60 - Train Loss: 0.0332, Val Loss: 0.1650, Val Pearson: 0.8440\n",
      "Validation loss did not improve for 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/60: 100%|██████████| 67/67 [02:07<00:00,  1.90s/it, train_loss=0.0339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/60 - Train Loss: 0.0339, Val Loss: 0.1852, Val Pearson: 0.8330\n",
      "Validation loss did not improve for 9 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/60: 100%|██████████| 67/67 [02:09<00:00,  1.93s/it, train_loss=0.0285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/60 - Train Loss: 0.0285, Val Loss: 0.1856, Val Pearson: 0.8334\n",
      "Validation loss did not improve for 10 epochs.\n",
      "Early stopping triggered at epoch 16. Loading best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-5f409c942542>:208: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Validation Pearson Coefficient  acc: 0.8407481002807617\n",
      "  Validation Pearson Coefficient flat acc: 0.8444429401851432\n",
      "  Test acc: 0.8068313148286608\n",
      "  Test Pearson Coefficient acc(flattened): 0.8187036644945287\n",
      "Fold 2/4\n",
      "(900, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   0%|          | 0/70 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60: 100%|██████████| 70/70 [02:14<00:00,  1.93s/it, train_loss=0.7436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60 - Train Loss: 0.7436, Val Loss: 0.4820, Val Pearson: 0.5720\n",
      "Validation loss improved from inf to 0.4820. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/60: 100%|██████████| 70/70 [02:13<00:00,  1.91s/it, train_loss=0.2384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/60 - Train Loss: 0.2384, Val Loss: 0.2624, Val Pearson: 0.7540\n",
      "Validation loss improved from 0.4820 to 0.2624. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/60: 100%|██████████| 70/70 [02:12<00:00,  1.89s/it, train_loss=0.1605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/60 - Train Loss: 0.1605, Val Loss: 0.2848, Val Pearson: 0.7390\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/60: 100%|██████████| 70/70 [02:13<00:00,  1.91s/it, train_loss=0.1238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/60 - Train Loss: 0.1238, Val Loss: 0.2843, Val Pearson: 0.7345\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/60: 100%|██████████| 70/70 [02:15<00:00,  1.93s/it, train_loss=0.0947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/60 - Train Loss: 0.0947, Val Loss: 0.3035, Val Pearson: 0.7129\n",
      "Validation loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/60: 100%|██████████| 70/70 [02:14<00:00,  1.92s/it, train_loss=0.0757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/60 - Train Loss: 0.0757, Val Loss: 0.2848, Val Pearson: 0.7305\n",
      "Validation loss did not improve for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/60: 100%|██████████| 70/70 [02:16<00:00,  1.95s/it, train_loss=0.0580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/60 - Train Loss: 0.0580, Val Loss: 0.2701, Val Pearson: 0.7436\n",
      "Validation loss did not improve for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/60: 100%|██████████| 70/70 [02:14<00:00,  1.93s/it, train_loss=0.0509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/60 - Train Loss: 0.0509, Val Loss: 0.3061, Val Pearson: 0.7152\n",
      "Validation loss did not improve for 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/60: 100%|██████████| 70/70 [02:13<00:00,  1.91s/it, train_loss=0.0450]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/60 - Train Loss: 0.0450, Val Loss: 0.2823, Val Pearson: 0.7323\n",
      "Validation loss did not improve for 7 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/60: 100%|██████████| 70/70 [02:17<00:00,  1.97s/it, train_loss=0.0356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/60 - Train Loss: 0.0356, Val Loss: 0.2823, Val Pearson: 0.7284\n",
      "Validation loss did not improve for 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/60: 100%|██████████| 70/70 [02:15<00:00,  1.93s/it, train_loss=0.0394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/60 - Train Loss: 0.0394, Val Loss: 0.2684, Val Pearson: 0.7452\n",
      "Validation loss did not improve for 9 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/60: 100%|██████████| 70/70 [02:14<00:00,  1.92s/it, train_loss=0.0309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/60 - Train Loss: 0.0309, Val Loss: 0.2820, Val Pearson: 0.7336\n",
      "Validation loss did not improve for 10 epochs.\n",
      "Early stopping triggered at epoch 12. Loading best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-5f409c942542>:208: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2:\n",
      "  Validation Pearson Coefficient  acc: 0.7376274881155594\n",
      "  Validation Pearson Coefficient flat acc: 0.7539924720269748\n",
      "  Test acc: 0.8144472320874532\n",
      "  Test Pearson Coefficient acc(flattened): 0.8206217674927101\n",
      "Fold 3/4\n",
      "(900, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   0%|          | 0/70 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60: 100%|██████████| 70/70 [02:14<00:00,  1.92s/it, train_loss=0.7808]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60 - Train Loss: 0.7808, Val Loss: 0.5202, Val Pearson: 0.5410\n",
      "Validation loss improved from inf to 0.5202. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/60: 100%|██████████| 70/70 [02:13<00:00,  1.91s/it, train_loss=0.2727]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/60 - Train Loss: 0.2727, Val Loss: 0.3196, Val Pearson: 0.6845\n",
      "Validation loss improved from 0.5202 to 0.3196. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/60: 100%|██████████| 70/70 [02:15<00:00,  1.93s/it, train_loss=0.1864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/60 - Train Loss: 0.1864, Val Loss: 0.3364, Val Pearson: 0.6625\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/60: 100%|██████████| 70/70 [02:13<00:00,  1.91s/it, train_loss=0.1545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/60 - Train Loss: 0.1545, Val Loss: 0.3081, Val Pearson: 0.6969\n",
      "Validation loss improved from 0.3196 to 0.3081. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/60: 100%|██████████| 70/70 [02:14<00:00,  1.92s/it, train_loss=0.1226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/60 - Train Loss: 0.1226, Val Loss: 0.3352, Val Pearson: 0.6674\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/60: 100%|██████████| 70/70 [02:13<00:00,  1.91s/it, train_loss=0.0894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/60 - Train Loss: 0.0894, Val Loss: 0.3341, Val Pearson: 0.6630\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/60: 100%|██████████| 70/70 [02:13<00:00,  1.91s/it, train_loss=0.0751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/60 - Train Loss: 0.0751, Val Loss: 0.3469, Val Pearson: 0.6543\n",
      "Validation loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/60: 100%|██████████| 70/70 [02:14<00:00,  1.92s/it, train_loss=0.0572]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/60 - Train Loss: 0.0572, Val Loss: 0.3100, Val Pearson: 0.6902\n",
      "Validation loss did not improve for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/60: 100%|██████████| 70/70 [02:13<00:00,  1.90s/it, train_loss=0.0464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/60 - Train Loss: 0.0464, Val Loss: 0.3251, Val Pearson: 0.6745\n",
      "Validation loss did not improve for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/60: 100%|██████████| 70/70 [02:14<00:00,  1.92s/it, train_loss=0.0381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/60 - Train Loss: 0.0381, Val Loss: 0.3263, Val Pearson: 0.6751\n",
      "Validation loss did not improve for 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/60: 100%|██████████| 70/70 [02:14<00:00,  1.92s/it, train_loss=0.0372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/60 - Train Loss: 0.0372, Val Loss: 0.3330, Val Pearson: 0.6696\n",
      "Validation loss did not improve for 7 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/60: 100%|██████████| 70/70 [02:13<00:00,  1.90s/it, train_loss=0.0332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/60 - Train Loss: 0.0332, Val Loss: 0.3226, Val Pearson: 0.6809\n",
      "Validation loss did not improve for 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/60: 100%|██████████| 70/70 [02:14<00:00,  1.92s/it, train_loss=0.0294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/60 - Train Loss: 0.0294, Val Loss: 0.3296, Val Pearson: 0.6699\n",
      "Validation loss did not improve for 9 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/60: 100%|██████████| 70/70 [02:12<00:00,  1.90s/it, train_loss=0.0266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/60 - Train Loss: 0.0266, Val Loss: 0.3289, Val Pearson: 0.6749\n",
      "Validation loss did not improve for 10 epochs.\n",
      "Early stopping triggered at epoch 14. Loading best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-5f409c942542>:208: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3:\n",
      "  Validation Pearson Coefficient  acc: 0.6918946608253147\n",
      "  Validation Pearson Coefficient flat acc: 0.6969476326705786\n",
      "  Test acc: 0.8040992577870687\n",
      "  Test Pearson Coefficient acc(flattened): 0.8153199017917342\n",
      "Fold 4/4\n",
      "(900, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   0%|          | 0/70 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60: 100%|██████████| 70/70 [02:15<00:00,  1.93s/it, train_loss=0.7181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60 - Train Loss: 0.7181, Val Loss: 0.5269, Val Pearson: 0.5855\n",
      "Validation loss improved from inf to 0.5269. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/60: 100%|██████████| 70/70 [02:14<00:00,  1.92s/it, train_loss=0.2376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/60 - Train Loss: 0.2376, Val Loss: 0.3257, Val Pearson: 0.6850\n",
      "Validation loss improved from 0.5269 to 0.3257. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/60: 100%|██████████| 70/70 [02:14<00:00,  1.92s/it, train_loss=0.1800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/60 - Train Loss: 0.1800, Val Loss: 0.3300, Val Pearson: 0.6822\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/60: 100%|██████████| 70/70 [02:14<00:00,  1.93s/it, train_loss=0.1331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/60 - Train Loss: 0.1331, Val Loss: 0.3367, Val Pearson: 0.6767\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/60: 100%|██████████| 70/70 [02:13<00:00,  1.91s/it, train_loss=0.0999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/60 - Train Loss: 0.0999, Val Loss: 0.3143, Val Pearson: 0.6936\n",
      "Validation loss improved from 0.3257 to 0.3143. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/60: 100%|██████████| 70/70 [02:14<00:00,  1.92s/it, train_loss=0.0768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/60 - Train Loss: 0.0768, Val Loss: 0.3215, Val Pearson: 0.6941\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/60: 100%|██████████| 70/70 [02:15<00:00,  1.94s/it, train_loss=0.0626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/60 - Train Loss: 0.0626, Val Loss: 0.3023, Val Pearson: 0.7080\n",
      "Validation loss improved from 0.3143 to 0.3023. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/60: 100%|██████████| 70/70 [02:14<00:00,  1.92s/it, train_loss=0.0557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/60 - Train Loss: 0.0557, Val Loss: 0.3185, Val Pearson: 0.6966\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/60: 100%|██████████| 70/70 [02:13<00:00,  1.91s/it, train_loss=0.0515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/60 - Train Loss: 0.0515, Val Loss: 0.3020, Val Pearson: 0.7109\n",
      "Validation loss improved from 0.3023 to 0.3020. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/60: 100%|██████████| 70/70 [02:14<00:00,  1.93s/it, train_loss=0.0424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/60 - Train Loss: 0.0424, Val Loss: 0.3194, Val Pearson: 0.6954\n",
      "Validation loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/60: 100%|██████████| 70/70 [02:13<00:00,  1.91s/it, train_loss=0.0450]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/60 - Train Loss: 0.0450, Val Loss: 0.3250, Val Pearson: 0.6934\n",
      "Validation loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/60: 100%|██████████| 70/70 [02:13<00:00,  1.91s/it, train_loss=0.0438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/60 - Train Loss: 0.0438, Val Loss: 0.3186, Val Pearson: 0.6985\n",
      "Validation loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/60: 100%|██████████| 70/70 [02:15<00:00,  1.94s/it, train_loss=0.0305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/60 - Train Loss: 0.0305, Val Loss: 0.3190, Val Pearson: 0.6993\n",
      "Validation loss did not improve for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/60: 100%|██████████| 70/70 [02:13<00:00,  1.91s/it, train_loss=0.0327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/60 - Train Loss: 0.0327, Val Loss: 0.3196, Val Pearson: 0.6945\n",
      "Validation loss did not improve for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/60: 100%|██████████| 70/70 [02:14<00:00,  1.92s/it, train_loss=0.0285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/60 - Train Loss: 0.0285, Val Loss: 0.3159, Val Pearson: 0.7037\n",
      "Validation loss did not improve for 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/60: 100%|██████████| 70/70 [02:15<00:00,  1.94s/it, train_loss=0.0264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/60 - Train Loss: 0.0264, Val Loss: 0.3236, Val Pearson: 0.6954\n",
      "Validation loss did not improve for 7 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/60: 100%|██████████| 70/70 [02:15<00:00,  1.94s/it, train_loss=0.0197]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/60 - Train Loss: 0.0197, Val Loss: 0.3190, Val Pearson: 0.6990\n",
      "Validation loss did not improve for 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/60: 100%|██████████| 70/70 [02:13<00:00,  1.91s/it, train_loss=0.0189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/60 - Train Loss: 0.0189, Val Loss: 0.3197, Val Pearson: 0.6954\n",
      "Validation loss did not improve for 9 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/60: 100%|██████████| 70/70 [02:14<00:00,  1.92s/it, train_loss=0.0186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/60 - Train Loss: 0.0186, Val Loss: 0.3251, Val Pearson: 0.6928\n",
      "Validation loss did not improve for 10 epochs.\n",
      "Early stopping triggered at epoch 19. Loading best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-5f409c942542>:208: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n",
      "/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4:\n",
      "  Validation Pearson Coefficient  acc: 0.6979680061340332\n",
      "  Validation Pearson Coefficient flat acc: 0.7109361224983757\n",
      "  Test acc: 0.806722899278005\n",
      "  Test Pearson Coefficient acc(flattened): 0.8146534796330512\n",
      "\n",
      "Training completed.\n",
      "Average metrics across all folds:\n",
      "  val_prc_acc: 0.7420595638389174\n",
      "  val_prc_acc_flat: 0.7515797918452681\n",
      "  test_acc: 0.8080251759952969\n",
      "  test_prc_flat: 0.8173247033530061\n",
      "  Fold: Average\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ll60k\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "            \"RespBertCNNModelV2\": {\n",
    "            'model' : RespBertCNNModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"output_size\": None  \n",
    "        },\n",
    "            \"RespBertLSTMModelV2\": {\n",
    "            'model': RespBertLSTMModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 3,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 60\n",
    "    batch_size = 13\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertCNNModelV2\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    #processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c49776-4d25-444f-bb41-91f44589f20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   0%|          | 0/67 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60:  33%|███▎      | 22/67 [00:44<01:27,  1.95s/it, train_loss=0.9990]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ll60k\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "            \"RespBertCNNModelV2\": {\n",
    "            'model' : RespBertCNNModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"output_size\": None  \n",
    "        },\n",
    "            \"RespBertLSTMModelV2\": {\n",
    "            'model': RespBertLSTMModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 3,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "            ,\n",
    "            \"RespBertLSTMCNNTransformerModel\": {\n",
    "            'model': RespBertLSTMCNNTransformerModel,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 1024,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 60\n",
    "    batch_size = 13\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertCNNModelV2\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    #processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f889e3d-b879-4c28-8ef9-1f2d1dc35f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Epoch 1/60:   0%|          | 0/67 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60:   0%|          | 0/67 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacity of 93.12 GiB of which 218.75 MiB is free. Including non-PyTorch memory, this process has 92.90 GiB memory in use. Of the allocated memory 91.37 GiB is allocated by PyTorch, and 882.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:355\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39m## same wav2vec2 base model and pipeline used in the paper\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39m#processor = AutoProcessor.from_pretrained(config[\"model_name\"])\u001b[39;00m\n\u001b[1;32m    353\u001b[0m processor \u001b[39m=\u001b[39m Wav2Vec2FeatureExtractor\u001b[39m.\u001b[39mfrom_pretrained(config[\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 355\u001b[0m train(\n\u001b[1;32m    356\u001b[0m     path_to_data\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/wav/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    357\u001b[0m     path_to_labels\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/lab/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    358\u001b[0m     window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    359\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    360\u001b[0m     config \u001b[39m=\u001b[39;49m config,\n\u001b[1;32m    361\u001b[0m     step_size\u001b[39m=\u001b[39;49mstep_size,\n\u001b[1;32m    362\u001b[0m     data_parts\u001b[39m=\u001b[39;49m data_parts ,\n\u001b[1;32m    363\u001b[0m     early_stopping_patience\u001b[39m=\u001b[39;49m early_stopping_patience,\n\u001b[1;32m    364\u001b[0m     epochs\u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    365\u001b[0m     processor \u001b[39m=\u001b[39;49m processor\n\u001b[1;32m    366\u001b[0m )\n",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:146\u001b[0m\n\u001b[1;32m    144\u001b[0m input_values \u001b[39m=\u001b[39m batch_d\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    145\u001b[0m batch_lbs \u001b[39m=\u001b[39m batch_lbs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 146\u001b[0m outputs \u001b[39m=\u001b[39m model(input_values)\n\u001b[1;32m    147\u001b[0m loss \u001b[39m=\u001b[39m correlation_coefficient_loss(outputs, batch_lbs)\n\u001b[1;32m    148\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/home3/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_models.py:787\u001b[0m, in \u001b[0;36mRespBertLSTMCNNTransformerModel.forward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_values):\n\u001b[0;32m--> 787\u001b[0m     wav \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwav_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minput_values)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    788\u001b[0m     cnn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcnn(wav\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m    789\u001b[0m     lstm_output, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(wav)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:1228\u001b[0m, in \u001b[0;36mWavLMModel.forward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1223\u001b[0m hidden_states, extract_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_projection(extract_features)\n\u001b[1;32m   1224\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mask_hidden_states(\n\u001b[1;32m   1225\u001b[0m     hidden_states, mask_time_indices\u001b[39m=\u001b[39mmask_time_indices, attention_mask\u001b[39m=\u001b[39mattention_mask\n\u001b[1;32m   1226\u001b[0m )\n\u001b[0;32m-> 1228\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1229\u001b[0m     hidden_states,\n\u001b[1;32m   1230\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1231\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1232\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1233\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1234\u001b[0m )\n\u001b[1;32m   1236\u001b[0m hidden_states \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madapter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:808\u001b[0m, in \u001b[0;36mWavLMEncoderStableLayerNorm.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    800\u001b[0m         layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    801\u001b[0m             layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    802\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    805\u001b[0m             output_attentions,\n\u001b[1;32m    806\u001b[0m         )\n\u001b[1;32m    807\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 808\u001b[0m         layer_outputs \u001b[39m=\u001b[39m layer(\n\u001b[1;32m    809\u001b[0m             hidden_states,\n\u001b[1;32m    810\u001b[0m             attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    811\u001b[0m             output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    812\u001b[0m             position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    813\u001b[0m         )\n\u001b[1;32m    814\u001b[0m     hidden_states, position_bias \u001b[39m=\u001b[39m layer_outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    816\u001b[0m \u001b[39mif\u001b[39;00m skip_the_layer:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:651\u001b[0m, in \u001b[0;36mWavLMEncoderLayerStableLayerNorm.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, output_attentions)\u001b[0m\n\u001b[1;32m    649\u001b[0m attn_residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m    650\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 651\u001b[0m hidden_states, attn_weights, position_bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    652\u001b[0m     hidden_states,\n\u001b[1;32m    653\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    654\u001b[0m     position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    655\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    656\u001b[0m )\n\u001b[1;32m    657\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    658\u001b[0m hidden_states \u001b[39m=\u001b[39m attn_residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:474\u001b[0m, in \u001b[0;36mWavLMAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, output_attentions, index)\u001b[0m\n\u001b[1;32m    471\u001b[0m gated_position_bias \u001b[39m=\u001b[39m gate_output\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m position_bias\n\u001b[1;32m    472\u001b[0m gated_position_bias \u001b[39m=\u001b[39m gated_position_bias\u001b[39m.\u001b[39mview((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, tgt_len, tgt_len))\n\u001b[0;32m--> 474\u001b[0m attn_output, attn_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtorch_multi_head_self_attention(\n\u001b[1;32m    475\u001b[0m     hidden_states, attention_mask, gated_position_bias, output_attentions\n\u001b[1;32m    476\u001b[0m )\n\u001b[1;32m    478\u001b[0m \u001b[39mreturn\u001b[39;00m attn_output, attn_weights, position_bias\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:498\u001b[0m, in \u001b[0;36mWavLMAttention.torch_multi_head_self_attention\u001b[0;34m(self, hidden_states, attention_mask, gated_position_bias, output_attentions)\u001b[0m\n\u001b[1;32m    494\u001b[0m add_zero_attn \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[39m# PyTorch 1.3.0 has F.multi_head_attention_forward defined\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[39m# so no problem with backwards compatibility\u001b[39;00m\n\u001b[0;32m--> 498\u001b[0m attn_output, attn_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m    499\u001b[0m     query,\n\u001b[1;32m    500\u001b[0m     key,\n\u001b[1;32m    501\u001b[0m     value,\n\u001b[1;32m    502\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim,\n\u001b[1;32m    503\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m    504\u001b[0m     torch\u001b[39m.\u001b[39;49mempty([\u001b[39m0\u001b[39;49m]),\n\u001b[1;32m    505\u001b[0m     torch\u001b[39m.\u001b[39;49mcat((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_proj\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk_proj\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_proj\u001b[39m.\u001b[39;49mbias)),\n\u001b[1;32m    506\u001b[0m     bias_k,\n\u001b[1;32m    507\u001b[0m     bias_v,\n\u001b[1;32m    508\u001b[0m     add_zero_attn,\n\u001b[1;32m    509\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout,\n\u001b[1;32m    510\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    511\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    512\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m    513\u001b[0m     key_padding_mask,\n\u001b[1;32m    514\u001b[0m     output_attentions,\n\u001b[1;32m    515\u001b[0m     gated_position_bias,\n\u001b[1;32m    516\u001b[0m     use_separate_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    517\u001b[0m     q_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    518\u001b[0m     k_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    519\u001b[0m     v_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    520\u001b[0m )\n\u001b[1;32m    522\u001b[0m \u001b[39m# [Seq_Len, Batch Size, ...] -> [Batch Size, Seq_Len, ...]\u001b[39;00m\n\u001b[1;32m    523\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5560\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5557\u001b[0m k \u001b[39m=\u001b[39m k\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m   5558\u001b[0m v \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 5560\u001b[0m attn_output \u001b[39m=\u001b[39m scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n\u001b[1;32m   5561\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m   5563\u001b[0m attn_output \u001b[39m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacity of 93.12 GiB of which 218.75 MiB is free. Including non-PyTorch memory, this process has 92.90 GiB memory in use. Of the allocated memory 91.37 GiB is allocated by PyTorch, and 882.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ll60k\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "            \"RespBertCNNModelV2\": {\n",
    "            'model' : RespBertCNNModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"output_size\": None  \n",
    "        },\n",
    "            \"RespBertLSTMModelV2\": {\n",
    "            'model': RespBertLSTMModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 3,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "            ,\n",
    "            \"RespBertLSTMCNNTransformerModel\": {\n",
    "            'model': RespBertLSTMCNNTransformerModel,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 1024,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 60\n",
    "    batch_size = 13\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertLSTMCNNTransformerModel\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    #processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a51cfd5-4ab4-4ce0-9b5b-96941ba38e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Epoch 1/60:   0%|          | 0/87 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60:   0%|          | 0/87 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "was expecting embedding dimension of 3072, but got 1499",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:355\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39m## same wav2vec2 base model and pipeline used in the paper\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39m#processor = AutoProcessor.from_pretrained(config[\"model_name\"])\u001b[39;00m\n\u001b[1;32m    353\u001b[0m processor \u001b[39m=\u001b[39m Wav2Vec2FeatureExtractor\u001b[39m.\u001b[39mfrom_pretrained(config[\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 355\u001b[0m train(\n\u001b[1;32m    356\u001b[0m     path_to_data\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/wav/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    357\u001b[0m     path_to_labels\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/lab/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    358\u001b[0m     window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    359\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    360\u001b[0m     config \u001b[39m=\u001b[39;49m config,\n\u001b[1;32m    361\u001b[0m     step_size\u001b[39m=\u001b[39;49mstep_size,\n\u001b[1;32m    362\u001b[0m     data_parts\u001b[39m=\u001b[39;49m data_parts ,\n\u001b[1;32m    363\u001b[0m     early_stopping_patience\u001b[39m=\u001b[39;49m early_stopping_patience,\n\u001b[1;32m    364\u001b[0m     epochs\u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    365\u001b[0m     processor \u001b[39m=\u001b[39;49m processor\n\u001b[1;32m    366\u001b[0m )\n",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:146\u001b[0m\n\u001b[1;32m    144\u001b[0m input_values \u001b[39m=\u001b[39m batch_d\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    145\u001b[0m batch_lbs \u001b[39m=\u001b[39m batch_lbs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 146\u001b[0m outputs \u001b[39m=\u001b[39m model(input_values)\n\u001b[1;32m    147\u001b[0m loss \u001b[39m=\u001b[39m correlation_coefficient_loss(outputs, batch_lbs)\n\u001b[1;32m    148\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/home3/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_models.py:798\u001b[0m, in \u001b[0;36mRespBertLSTMCNNTransformerModel.forward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    795\u001b[0m combined_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((cnn_output\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m), lstm_output, wav_projected), dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    797\u001b[0m \u001b[39m# Pass combined output through Transformer layers\u001b[39;00m\n\u001b[0;32m--> 798\u001b[0m transformer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(combined_output\u001b[39m.\u001b[39;49mtranspose(\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m))\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    800\u001b[0m \u001b[39m# Final fully connected layer\u001b[39;00m\n\u001b[1;32m    801\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(transformer_output[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :])\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:416\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    413\u001b[0m is_causal \u001b[39m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    415\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 416\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, is_causal\u001b[39m=\u001b[39;49mis_causal, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[1;32m    418\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    419\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m, src\u001b[39m.\u001b[39msize())\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:749\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    747\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x))\n\u001b[1;32m    748\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 749\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[39m=\u001b[39;49mis_causal))\n\u001b[1;32m    750\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[1;32m    752\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:757\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sa_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor,\n\u001b[1;32m    756\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 757\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(x, x, x,\n\u001b[1;32m    758\u001b[0m                        attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m    759\u001b[0m                        key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m    760\u001b[0m                        need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, is_causal\u001b[39m=\u001b[39;49mis_causal)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    761\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/activation.py:1275\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1262\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1263\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1273\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[1;32m   1274\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1275\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m   1276\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m   1277\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[1;32m   1278\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[1;32m   1279\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m   1280\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m   1281\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m   1282\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[1;32m   1283\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m   1284\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[1;32m   1285\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n\u001b[1;32m   1286\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[1;32m   1287\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5400\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5394\u001b[0m     \u001b[39mif\u001b[39;00m key_padding_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5395\u001b[0m         \u001b[39m# We have the attn_mask, and use that to merge kpm into it.\u001b[39;00m\n\u001b[1;32m   5396\u001b[0m         \u001b[39m# Turn off use of is_causal hint, as the merged mask is no\u001b[39;00m\n\u001b[1;32m   5397\u001b[0m         \u001b[39m# longer causal.\u001b[39;00m\n\u001b[1;32m   5398\u001b[0m         is_causal \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 5400\u001b[0m \u001b[39massert\u001b[39;00m embed_dim \u001b[39m==\u001b[39m embed_dim_to_check, \\\n\u001b[1;32m   5401\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwas expecting embedding dimension of \u001b[39m\u001b[39m{\u001b[39;00membed_dim_to_check\u001b[39m}\u001b[39;00m\u001b[39m, but got \u001b[39m\u001b[39m{\u001b[39;00membed_dim\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   5402\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(embed_dim, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m   5403\u001b[0m     \u001b[39m# embed_dim can be a tensor when JIT tracing\u001b[39;00m\n\u001b[1;32m   5404\u001b[0m     head_dim \u001b[39m=\u001b[39m embed_dim\u001b[39m.\u001b[39mdiv(num_heads, rounding_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrunc\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: was expecting embedding dimension of 3072, but got 1499"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ll60k\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "            \"RespBertCNNModelV2\": {\n",
    "            'model' : RespBertCNNModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"output_size\": None  \n",
    "        },\n",
    "            \"RespBertLSTMModelV2\": {\n",
    "            'model': RespBertLSTMModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 3,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "            ,\n",
    "            \"RespBertLSTMCNNTransformerModel\": {\n",
    "            'model': RespBertLSTMCNNTransformerModel,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 1024,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 60\n",
    "    batch_size = 10\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertLSTMCNNTransformerModel\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    #processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a43ed3-6e8b-401f-aeb5-3321314196c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Epoch 1/60:   0%|          | 0/87 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60:   0%|          | 0/87 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "was expecting embedding dimension of 3072, but got 1499",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:355\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39m## same wav2vec2 base model and pipeline used in the paper\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39m#processor = AutoProcessor.from_pretrained(config[\"model_name\"])\u001b[39;00m\n\u001b[1;32m    353\u001b[0m processor \u001b[39m=\u001b[39m Wav2Vec2FeatureExtractor\u001b[39m.\u001b[39mfrom_pretrained(config[\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 355\u001b[0m train(\n\u001b[1;32m    356\u001b[0m     path_to_data\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/wav/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    357\u001b[0m     path_to_labels\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/lab/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    358\u001b[0m     window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    359\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    360\u001b[0m     config \u001b[39m=\u001b[39;49m config,\n\u001b[1;32m    361\u001b[0m     step_size\u001b[39m=\u001b[39;49mstep_size,\n\u001b[1;32m    362\u001b[0m     data_parts\u001b[39m=\u001b[39;49m data_parts ,\n\u001b[1;32m    363\u001b[0m     early_stopping_patience\u001b[39m=\u001b[39;49m early_stopping_patience,\n\u001b[1;32m    364\u001b[0m     epochs\u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    365\u001b[0m     processor \u001b[39m=\u001b[39;49m processor\n\u001b[1;32m    366\u001b[0m )\n",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:146\u001b[0m\n\u001b[1;32m    144\u001b[0m input_values \u001b[39m=\u001b[39m batch_d\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    145\u001b[0m batch_lbs \u001b[39m=\u001b[39m batch_lbs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 146\u001b[0m outputs \u001b[39m=\u001b[39m model(input_values)\n\u001b[1;32m    147\u001b[0m loss \u001b[39m=\u001b[39m correlation_coefficient_loss(outputs, batch_lbs)\n\u001b[1;32m    148\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/home3/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_models.py:799\u001b[0m, in \u001b[0;36mRespBertLSTMCNNTransformerModel.forward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[39mprint\u001b[39m(combined_output\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    798\u001b[0m \u001b[39m# Pass combined output through Transformer layers\u001b[39;00m\n\u001b[0;32m--> 799\u001b[0m transformer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(combined_output\u001b[39m.\u001b[39;49mtranspose(\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m))\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    801\u001b[0m \u001b[39m# Final fully connected layer\u001b[39;00m\n\u001b[1;32m    802\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(transformer_output[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :])\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:416\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    413\u001b[0m is_causal \u001b[39m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    415\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 416\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, is_causal\u001b[39m=\u001b[39;49mis_causal, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[1;32m    418\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    419\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m, src\u001b[39m.\u001b[39msize())\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:749\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    747\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x))\n\u001b[1;32m    748\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 749\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[39m=\u001b[39;49mis_causal))\n\u001b[1;32m    750\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[1;32m    752\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:757\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sa_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor,\n\u001b[1;32m    756\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 757\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(x, x, x,\n\u001b[1;32m    758\u001b[0m                        attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m    759\u001b[0m                        key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m    760\u001b[0m                        need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, is_causal\u001b[39m=\u001b[39;49mis_causal)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    761\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/activation.py:1275\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1262\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1263\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1273\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[1;32m   1274\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1275\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m   1276\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m   1277\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[1;32m   1278\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[1;32m   1279\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m   1280\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m   1281\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m   1282\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[1;32m   1283\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m   1284\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[1;32m   1285\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n\u001b[1;32m   1286\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[1;32m   1287\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5400\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5394\u001b[0m     \u001b[39mif\u001b[39;00m key_padding_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5395\u001b[0m         \u001b[39m# We have the attn_mask, and use that to merge kpm into it.\u001b[39;00m\n\u001b[1;32m   5396\u001b[0m         \u001b[39m# Turn off use of is_causal hint, as the merged mask is no\u001b[39;00m\n\u001b[1;32m   5397\u001b[0m         \u001b[39m# longer causal.\u001b[39;00m\n\u001b[1;32m   5398\u001b[0m         is_causal \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 5400\u001b[0m \u001b[39massert\u001b[39;00m embed_dim \u001b[39m==\u001b[39m embed_dim_to_check, \\\n\u001b[1;32m   5401\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwas expecting embedding dimension of \u001b[39m\u001b[39m{\u001b[39;00membed_dim_to_check\u001b[39m}\u001b[39;00m\u001b[39m, but got \u001b[39m\u001b[39m{\u001b[39;00membed_dim\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   5402\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(embed_dim, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m   5403\u001b[0m     \u001b[39m# embed_dim can be a tensor when JIT tracing\u001b[39;00m\n\u001b[1;32m   5404\u001b[0m     head_dim \u001b[39m=\u001b[39m embed_dim\u001b[39m.\u001b[39mdiv(num_heads, rounding_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrunc\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: was expecting embedding dimension of 3072, but got 1499"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ll60k\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "            \"RespBertCNNModelV2\": {\n",
    "            'model' : RespBertCNNModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"output_size\": None  \n",
    "        },\n",
    "            \"RespBertLSTMModelV2\": {\n",
    "            'model': RespBertLSTMModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 3,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "            ,\n",
    "            \"RespBertLSTMCNNTransformerModel\": {\n",
    "            'model': RespBertLSTMCNNTransformerModel,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 1024,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 60\n",
    "    batch_size = 10\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertLSTMCNNTransformerModel\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    #processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1dd23e-98b9-4e8d-8bf5-f7218d052e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Epoch 1/60:   0%|          | 0/87 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60:   0%|          | 0/87 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "was expecting embedding dimension of 3072, but got 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:355\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39m## same wav2vec2 base model and pipeline used in the paper\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39m#processor = AutoProcessor.from_pretrained(config[\"model_name\"])\u001b[39;00m\n\u001b[1;32m    353\u001b[0m processor \u001b[39m=\u001b[39m Wav2Vec2FeatureExtractor\u001b[39m.\u001b[39mfrom_pretrained(config[\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 355\u001b[0m train(\n\u001b[1;32m    356\u001b[0m     path_to_data\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/wav/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    357\u001b[0m     path_to_labels\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/lab/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    358\u001b[0m     window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    359\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    360\u001b[0m     config \u001b[39m=\u001b[39;49m config,\n\u001b[1;32m    361\u001b[0m     step_size\u001b[39m=\u001b[39;49mstep_size,\n\u001b[1;32m    362\u001b[0m     data_parts\u001b[39m=\u001b[39;49m data_parts ,\n\u001b[1;32m    363\u001b[0m     early_stopping_patience\u001b[39m=\u001b[39;49m early_stopping_patience,\n\u001b[1;32m    364\u001b[0m     epochs\u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    365\u001b[0m     processor \u001b[39m=\u001b[39;49m processor\n\u001b[1;32m    366\u001b[0m )\n",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:146\u001b[0m\n\u001b[1;32m    144\u001b[0m input_values \u001b[39m=\u001b[39m batch_d\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    145\u001b[0m batch_lbs \u001b[39m=\u001b[39m batch_lbs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 146\u001b[0m outputs \u001b[39m=\u001b[39m model(input_values)\n\u001b[1;32m    147\u001b[0m loss \u001b[39m=\u001b[39m correlation_coefficient_loss(outputs, batch_lbs)\n\u001b[1;32m    148\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/home3/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_models.py:802\u001b[0m, in \u001b[0;36mRespBertLSTMCNNTransformerModel.forward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[39mprint\u001b[39m(combined_output\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    801\u001b[0m \u001b[39m# Pass combined output through Transformer layers\u001b[39;00m\n\u001b[0;32m--> 802\u001b[0m transformer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(combined_output\u001b[39m.\u001b[39;49mtranspose(\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m))\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    803\u001b[0m \u001b[39mprint\u001b[39m(transformer_output\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    804\u001b[0m \u001b[39m# Final fully connected layer\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:416\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    413\u001b[0m is_causal \u001b[39m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    415\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 416\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, is_causal\u001b[39m=\u001b[39;49mis_causal, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[1;32m    418\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    419\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m, src\u001b[39m.\u001b[39msize())\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:749\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    747\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x))\n\u001b[1;32m    748\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 749\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[39m=\u001b[39;49mis_causal))\n\u001b[1;32m    750\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[1;32m    752\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:757\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sa_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor,\n\u001b[1;32m    756\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 757\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(x, x, x,\n\u001b[1;32m    758\u001b[0m                        attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m    759\u001b[0m                        key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m    760\u001b[0m                        need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, is_causal\u001b[39m=\u001b[39;49mis_causal)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    761\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/activation.py:1275\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1262\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1263\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1273\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[1;32m   1274\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1275\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m   1276\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m   1277\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[1;32m   1278\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[1;32m   1279\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m   1280\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m   1281\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m   1282\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[1;32m   1283\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m   1284\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[1;32m   1285\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n\u001b[1;32m   1286\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[1;32m   1287\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5400\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5394\u001b[0m     \u001b[39mif\u001b[39;00m key_padding_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5395\u001b[0m         \u001b[39m# We have the attn_mask, and use that to merge kpm into it.\u001b[39;00m\n\u001b[1;32m   5396\u001b[0m         \u001b[39m# Turn off use of is_causal hint, as the merged mask is no\u001b[39;00m\n\u001b[1;32m   5397\u001b[0m         \u001b[39m# longer causal.\u001b[39;00m\n\u001b[1;32m   5398\u001b[0m         is_causal \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 5400\u001b[0m \u001b[39massert\u001b[39;00m embed_dim \u001b[39m==\u001b[39m embed_dim_to_check, \\\n\u001b[1;32m   5401\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwas expecting embedding dimension of \u001b[39m\u001b[39m{\u001b[39;00membed_dim_to_check\u001b[39m}\u001b[39;00m\u001b[39m, but got \u001b[39m\u001b[39m{\u001b[39;00membed_dim\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   5402\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(embed_dim, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m   5403\u001b[0m     \u001b[39m# embed_dim can be a tensor when JIT tracing\u001b[39;00m\n\u001b[1;32m   5404\u001b[0m     head_dim \u001b[39m=\u001b[39m embed_dim\u001b[39m.\u001b[39mdiv(num_heads, rounding_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrunc\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: was expecting embedding dimension of 3072, but got 10"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ll60k\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "            \"RespBertCNNModelV2\": {\n",
    "            'model' : RespBertCNNModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"output_size\": None  \n",
    "        },\n",
    "            \"RespBertLSTMModelV2\": {\n",
    "            'model': RespBertLSTMModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 3,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "            ,\n",
    "            \"RespBertLSTMCNNTransformerModel\": {\n",
    "            'model': RespBertLSTMCNNTransformerModel,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 1024,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 60\n",
    "    batch_size = 10\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertLSTMCNNTransformerModel\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    #processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d7bed-b1dc-4ce9-8633-4908dd59cdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Epoch 1/60:   0%|          | 0/87 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60:   0%|          | 0/87 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.35 GiB. GPU 0 has a total capacity of 93.12 GiB of which 98.75 MiB is free. Including non-PyTorch memory, this process has 93.02 GiB memory in use. Of the allocated memory 91.01 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:355\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39m## same wav2vec2 base model and pipeline used in the paper\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39m#processor = AutoProcessor.from_pretrained(config[\"model_name\"])\u001b[39;00m\n\u001b[1;32m    353\u001b[0m processor \u001b[39m=\u001b[39m Wav2Vec2FeatureExtractor\u001b[39m.\u001b[39mfrom_pretrained(config[\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 355\u001b[0m train(\n\u001b[1;32m    356\u001b[0m     path_to_data\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/wav/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    357\u001b[0m     path_to_labels\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/lab/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    358\u001b[0m     window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    359\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    360\u001b[0m     config \u001b[39m=\u001b[39;49m config,\n\u001b[1;32m    361\u001b[0m     step_size\u001b[39m=\u001b[39;49mstep_size,\n\u001b[1;32m    362\u001b[0m     data_parts\u001b[39m=\u001b[39;49m data_parts ,\n\u001b[1;32m    363\u001b[0m     early_stopping_patience\u001b[39m=\u001b[39;49m early_stopping_patience,\n\u001b[1;32m    364\u001b[0m     epochs\u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    365\u001b[0m     processor \u001b[39m=\u001b[39;49m processor\n\u001b[1;32m    366\u001b[0m )\n",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:146\u001b[0m\n\u001b[1;32m    144\u001b[0m input_values \u001b[39m=\u001b[39m batch_d\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    145\u001b[0m batch_lbs \u001b[39m=\u001b[39m batch_lbs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 146\u001b[0m outputs \u001b[39m=\u001b[39m model(input_values)\n\u001b[1;32m    147\u001b[0m loss \u001b[39m=\u001b[39m correlation_coefficient_loss(outputs, batch_lbs)\n\u001b[1;32m    148\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/home3/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_models.py:787\u001b[0m, in \u001b[0;36mRespBertLSTMCNNTransformerModel.forward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_values):\n\u001b[0;32m--> 787\u001b[0m     wav \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwav_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minput_values)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    788\u001b[0m     cnn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcnn(wav\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m    789\u001b[0m     lstm_output, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(wav)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:1228\u001b[0m, in \u001b[0;36mWavLMModel.forward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1223\u001b[0m hidden_states, extract_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_projection(extract_features)\n\u001b[1;32m   1224\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mask_hidden_states(\n\u001b[1;32m   1225\u001b[0m     hidden_states, mask_time_indices\u001b[39m=\u001b[39mmask_time_indices, attention_mask\u001b[39m=\u001b[39mattention_mask\n\u001b[1;32m   1226\u001b[0m )\n\u001b[0;32m-> 1228\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1229\u001b[0m     hidden_states,\n\u001b[1;32m   1230\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1231\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1232\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1233\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1234\u001b[0m )\n\u001b[1;32m   1236\u001b[0m hidden_states \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madapter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:808\u001b[0m, in \u001b[0;36mWavLMEncoderStableLayerNorm.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    800\u001b[0m         layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    801\u001b[0m             layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    802\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    805\u001b[0m             output_attentions,\n\u001b[1;32m    806\u001b[0m         )\n\u001b[1;32m    807\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 808\u001b[0m         layer_outputs \u001b[39m=\u001b[39m layer(\n\u001b[1;32m    809\u001b[0m             hidden_states,\n\u001b[1;32m    810\u001b[0m             attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    811\u001b[0m             output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    812\u001b[0m             position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    813\u001b[0m         )\n\u001b[1;32m    814\u001b[0m     hidden_states, position_bias \u001b[39m=\u001b[39m layer_outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    816\u001b[0m \u001b[39mif\u001b[39;00m skip_the_layer:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:651\u001b[0m, in \u001b[0;36mWavLMEncoderLayerStableLayerNorm.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, output_attentions)\u001b[0m\n\u001b[1;32m    649\u001b[0m attn_residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m    650\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 651\u001b[0m hidden_states, attn_weights, position_bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    652\u001b[0m     hidden_states,\n\u001b[1;32m    653\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    654\u001b[0m     position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    655\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    656\u001b[0m )\n\u001b[1;32m    657\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    658\u001b[0m hidden_states \u001b[39m=\u001b[39m attn_residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:474\u001b[0m, in \u001b[0;36mWavLMAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, output_attentions, index)\u001b[0m\n\u001b[1;32m    471\u001b[0m gated_position_bias \u001b[39m=\u001b[39m gate_output\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m position_bias\n\u001b[1;32m    472\u001b[0m gated_position_bias \u001b[39m=\u001b[39m gated_position_bias\u001b[39m.\u001b[39mview((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, tgt_len, tgt_len))\n\u001b[0;32m--> 474\u001b[0m attn_output, attn_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtorch_multi_head_self_attention(\n\u001b[1;32m    475\u001b[0m     hidden_states, attention_mask, gated_position_bias, output_attentions\n\u001b[1;32m    476\u001b[0m )\n\u001b[1;32m    478\u001b[0m \u001b[39mreturn\u001b[39;00m attn_output, attn_weights, position_bias\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:498\u001b[0m, in \u001b[0;36mWavLMAttention.torch_multi_head_self_attention\u001b[0;34m(self, hidden_states, attention_mask, gated_position_bias, output_attentions)\u001b[0m\n\u001b[1;32m    494\u001b[0m add_zero_attn \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[39m# PyTorch 1.3.0 has F.multi_head_attention_forward defined\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[39m# so no problem with backwards compatibility\u001b[39;00m\n\u001b[0;32m--> 498\u001b[0m attn_output, attn_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m    499\u001b[0m     query,\n\u001b[1;32m    500\u001b[0m     key,\n\u001b[1;32m    501\u001b[0m     value,\n\u001b[1;32m    502\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim,\n\u001b[1;32m    503\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m    504\u001b[0m     torch\u001b[39m.\u001b[39;49mempty([\u001b[39m0\u001b[39;49m]),\n\u001b[1;32m    505\u001b[0m     torch\u001b[39m.\u001b[39;49mcat((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_proj\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk_proj\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_proj\u001b[39m.\u001b[39;49mbias)),\n\u001b[1;32m    506\u001b[0m     bias_k,\n\u001b[1;32m    507\u001b[0m     bias_v,\n\u001b[1;32m    508\u001b[0m     add_zero_attn,\n\u001b[1;32m    509\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout,\n\u001b[1;32m    510\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    511\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    512\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m    513\u001b[0m     key_padding_mask,\n\u001b[1;32m    514\u001b[0m     output_attentions,\n\u001b[1;32m    515\u001b[0m     gated_position_bias,\n\u001b[1;32m    516\u001b[0m     use_separate_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    517\u001b[0m     q_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    518\u001b[0m     k_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    519\u001b[0m     v_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    520\u001b[0m )\n\u001b[1;32m    522\u001b[0m \u001b[39m# [Seq_Len, Batch Size, ...] -> [Batch Size, Seq_Len, ...]\u001b[39;00m\n\u001b[1;32m    523\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5560\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5557\u001b[0m k \u001b[39m=\u001b[39m k\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m   5558\u001b[0m v \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 5560\u001b[0m attn_output \u001b[39m=\u001b[39m scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n\u001b[1;32m   5561\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m   5563\u001b[0m attn_output \u001b[39m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 0 has a total capacity of 93.12 GiB of which 98.75 MiB is free. Including non-PyTorch memory, this process has 93.02 GiB memory in use. Of the allocated memory 91.01 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ll60k\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "            \"RespBertCNNModelV2\": {\n",
    "            'model' : RespBertCNNModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"output_size\": None  \n",
    "        },\n",
    "            \"RespBertLSTMModelV2\": {\n",
    "            'model': RespBertLSTMModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 3,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "            ,\n",
    "            \"RespBertLSTMCNNTransformerModel\": {\n",
    "            'model': RespBertLSTMCNNTransformerModel,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 1024,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 60\n",
    "    batch_size = 10\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertLSTMCNNTransformerModel\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    #processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de878248-8d60-44e6-84b8-2e3e45e86d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Epoch 1/60:   0%|          | 0/87 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60:   0%|          | 0/87 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 1499, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "was expecting embedding dimension of 3072, but got 1499",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:355\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39m## same wav2vec2 base model and pipeline used in the paper\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39m#processor = AutoProcessor.from_pretrained(config[\"model_name\"])\u001b[39;00m\n\u001b[1;32m    353\u001b[0m processor \u001b[39m=\u001b[39m Wav2Vec2FeatureExtractor\u001b[39m.\u001b[39mfrom_pretrained(config[\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 355\u001b[0m train(\n\u001b[1;32m    356\u001b[0m     path_to_data\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/wav/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    357\u001b[0m     path_to_labels\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/lab/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    358\u001b[0m     window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    359\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    360\u001b[0m     config \u001b[39m=\u001b[39;49m config,\n\u001b[1;32m    361\u001b[0m     step_size\u001b[39m=\u001b[39;49mstep_size,\n\u001b[1;32m    362\u001b[0m     data_parts\u001b[39m=\u001b[39;49m data_parts ,\n\u001b[1;32m    363\u001b[0m     early_stopping_patience\u001b[39m=\u001b[39;49m early_stopping_patience,\n\u001b[1;32m    364\u001b[0m     epochs\u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    365\u001b[0m     processor \u001b[39m=\u001b[39;49m processor\n\u001b[1;32m    366\u001b[0m )\n",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:146\u001b[0m\n\u001b[1;32m    144\u001b[0m input_values \u001b[39m=\u001b[39m batch_d\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    145\u001b[0m batch_lbs \u001b[39m=\u001b[39m batch_lbs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 146\u001b[0m outputs \u001b[39m=\u001b[39m model(input_values)\n\u001b[1;32m    147\u001b[0m loss \u001b[39m=\u001b[39m correlation_coefficient_loss(outputs, batch_lbs)\n\u001b[1;32m    148\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/home3/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_models.py:802\u001b[0m, in \u001b[0;36mRespBertLSTMCNNTransformerModel.forward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[39mprint\u001b[39m(combined_output\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    801\u001b[0m \u001b[39m# Pass combined output through Transformer layers\u001b[39;00m\n\u001b[0;32m--> 802\u001b[0m transformer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(combined_output\u001b[39m.\u001b[39;49mtranspose(\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m))\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    803\u001b[0m \u001b[39mprint\u001b[39m(transformer_output\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    804\u001b[0m \u001b[39m# Final fully connected layer\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:416\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    413\u001b[0m is_causal \u001b[39m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    415\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 416\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, is_causal\u001b[39m=\u001b[39;49mis_causal, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[1;32m    418\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    419\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m, src\u001b[39m.\u001b[39msize())\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:749\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    747\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x))\n\u001b[1;32m    748\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 749\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[39m=\u001b[39;49mis_causal))\n\u001b[1;32m    750\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[1;32m    752\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:757\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sa_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor,\n\u001b[1;32m    756\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 757\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(x, x, x,\n\u001b[1;32m    758\u001b[0m                        attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m    759\u001b[0m                        key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m    760\u001b[0m                        need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, is_causal\u001b[39m=\u001b[39;49mis_causal)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    761\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/activation.py:1275\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1262\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1263\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1273\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[1;32m   1274\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1275\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m   1276\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m   1277\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[1;32m   1278\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[1;32m   1279\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m   1280\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m   1281\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m   1282\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[1;32m   1283\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m   1284\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[1;32m   1285\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n\u001b[1;32m   1286\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[1;32m   1287\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5400\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5394\u001b[0m     \u001b[39mif\u001b[39;00m key_padding_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5395\u001b[0m         \u001b[39m# We have the attn_mask, and use that to merge kpm into it.\u001b[39;00m\n\u001b[1;32m   5396\u001b[0m         \u001b[39m# Turn off use of is_causal hint, as the merged mask is no\u001b[39;00m\n\u001b[1;32m   5397\u001b[0m         \u001b[39m# longer causal.\u001b[39;00m\n\u001b[1;32m   5398\u001b[0m         is_causal \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 5400\u001b[0m \u001b[39massert\u001b[39;00m embed_dim \u001b[39m==\u001b[39m embed_dim_to_check, \\\n\u001b[1;32m   5401\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwas expecting embedding dimension of \u001b[39m\u001b[39m{\u001b[39;00membed_dim_to_check\u001b[39m}\u001b[39;00m\u001b[39m, but got \u001b[39m\u001b[39m{\u001b[39;00membed_dim\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   5402\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(embed_dim, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m   5403\u001b[0m     \u001b[39m# embed_dim can be a tensor when JIT tracing\u001b[39;00m\n\u001b[1;32m   5404\u001b[0m     head_dim \u001b[39m=\u001b[39m embed_dim\u001b[39m.\u001b[39mdiv(num_heads, rounding_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrunc\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: was expecting embedding dimension of 3072, but got 1499"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ll60k\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "            \"RespBertCNNModelV2\": {\n",
    "            'model' : RespBertCNNModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"output_size\": None  \n",
    "        },\n",
    "            \"RespBertLSTMModelV2\": {\n",
    "            'model': RespBertLSTMModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 3,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "            ,\n",
    "            \"RespBertLSTMCNNTransformerModel\": {\n",
    "            'model': RespBertLSTMCNNTransformerModel,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 1024,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 60\n",
    "    batch_size = 10\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertLSTMCNNTransformerModel\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    #processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f3a33f-c99d-4fc7-a029-5eb6d19b123e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Epoch 1/60:   0%|          | 0/87 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60:   0%|          | 0/87 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 1499, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "transpose() received an invalid combination of arguments - got (int, int, int), but expected one of:\n * (int dim0, int dim1)\n * (name dim0, name dim1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:355\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39m## same wav2vec2 base model and pipeline used in the paper\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39m#processor = AutoProcessor.from_pretrained(config[\"model_name\"])\u001b[39;00m\n\u001b[1;32m    353\u001b[0m processor \u001b[39m=\u001b[39m Wav2Vec2FeatureExtractor\u001b[39m.\u001b[39mfrom_pretrained(config[\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 355\u001b[0m train(\n\u001b[1;32m    356\u001b[0m     path_to_data\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/wav/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    357\u001b[0m     path_to_labels\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/lab/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    358\u001b[0m     window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    359\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    360\u001b[0m     config \u001b[39m=\u001b[39;49m config,\n\u001b[1;32m    361\u001b[0m     step_size\u001b[39m=\u001b[39;49mstep_size,\n\u001b[1;32m    362\u001b[0m     data_parts\u001b[39m=\u001b[39;49m data_parts ,\n\u001b[1;32m    363\u001b[0m     early_stopping_patience\u001b[39m=\u001b[39;49m early_stopping_patience,\n\u001b[1;32m    364\u001b[0m     epochs\u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    365\u001b[0m     processor \u001b[39m=\u001b[39;49m processor\n\u001b[1;32m    366\u001b[0m )\n",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:146\u001b[0m\n\u001b[1;32m    144\u001b[0m input_values \u001b[39m=\u001b[39m batch_d\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    145\u001b[0m batch_lbs \u001b[39m=\u001b[39m batch_lbs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 146\u001b[0m outputs \u001b[39m=\u001b[39m model(input_values)\n\u001b[1;32m    147\u001b[0m loss \u001b[39m=\u001b[39m correlation_coefficient_loss(outputs, batch_lbs)\n\u001b[1;32m    148\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/home3/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_models.py:802\u001b[0m, in \u001b[0;36mRespBertLSTMCNNTransformerModel.forward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[39mprint\u001b[39m(combined_output\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    801\u001b[0m \u001b[39m# Pass combined output through Transformer layers\u001b[39;00m\n\u001b[0;32m--> 802\u001b[0m transformer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer(combined_output\u001b[39m.\u001b[39;49mtranspose(\u001b[39m1\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m2\u001b[39;49m))\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[1;32m    803\u001b[0m \u001b[39mprint\u001b[39m(transformer_output\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    804\u001b[0m \u001b[39m# Final fully connected layer\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: transpose() received an invalid combination of arguments - got (int, int, int), but expected one of:\n * (int dim0, int dim1)\n * (name dim0, name dim1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ll60k\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "            \"RespBertCNNModelV2\": {\n",
    "            'model' : RespBertCNNModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"output_size\": None  \n",
    "        },\n",
    "            \"RespBertLSTMModelV2\": {\n",
    "            'model': RespBertLSTMModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 3,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "            ,\n",
    "            \"RespBertLSTMCNNTransformerModel\": {\n",
    "            'model': RespBertLSTMCNNTransformerModel,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 1024,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 60\n",
    "    batch_size = 10\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertLSTMCNNTransformerModel\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    #processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a8456-48da-4fbd-9099-3e269cf538ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Epoch 1/60:   0%|          | 0/87 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60:   0%|          | 0/87 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([1499, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1499) must match the size of tensor b (10) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:355\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39m## same wav2vec2 base model and pipeline used in the paper\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39m#processor = AutoProcessor.from_pretrained(config[\"model_name\"])\u001b[39;00m\n\u001b[1;32m    353\u001b[0m processor \u001b[39m=\u001b[39m Wav2Vec2FeatureExtractor\u001b[39m.\u001b[39mfrom_pretrained(config[\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 355\u001b[0m train(\n\u001b[1;32m    356\u001b[0m     path_to_data\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/wav/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    357\u001b[0m     path_to_labels\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/lab/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    358\u001b[0m     window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    359\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    360\u001b[0m     config \u001b[39m=\u001b[39;49m config,\n\u001b[1;32m    361\u001b[0m     step_size\u001b[39m=\u001b[39;49mstep_size,\n\u001b[1;32m    362\u001b[0m     data_parts\u001b[39m=\u001b[39;49m data_parts ,\n\u001b[1;32m    363\u001b[0m     early_stopping_patience\u001b[39m=\u001b[39;49m early_stopping_patience,\n\u001b[1;32m    364\u001b[0m     epochs\u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    365\u001b[0m     processor \u001b[39m=\u001b[39;49m processor\n\u001b[1;32m    366\u001b[0m )\n",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:147\u001b[0m\n\u001b[1;32m    145\u001b[0m batch_lbs \u001b[39m=\u001b[39m batch_lbs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    146\u001b[0m outputs \u001b[39m=\u001b[39m model(input_values)\n\u001b[0;32m--> 147\u001b[0m loss \u001b[39m=\u001b[39m correlation_coefficient_loss(outputs, batch_lbs)\n\u001b[1;32m    148\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    149\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m/gpfs/home3/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_utils.py:444\u001b[0m, in \u001b[0;36mcorrelation_coefficient_loss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    442\u001b[0m my\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mmean(y, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    443\u001b[0m xm,ym\u001b[39m=\u001b[39mx\u001b[39m-\u001b[39mmx,y\u001b[39m-\u001b[39mmy\n\u001b[0;32m--> 444\u001b[0m r_num\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39;49mmultiply(xm, ym), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    445\u001b[0m sum_square_x\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39msquare(xm), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    446\u001b[0m sum_square_y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39msquare(ym), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1499) must match the size of tensor b (10) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ll60k\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "            \"RespBertCNNModelV2\": {\n",
    "            'model' : RespBertCNNModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"output_size\": None  \n",
    "        },\n",
    "            \"RespBertLSTMModelV2\": {\n",
    "            'model': RespBertLSTMModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 3,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "            ,\n",
    "            \"RespBertLSTMCNNTransformerModel\": {\n",
    "            'model': RespBertLSTMCNNTransformerModel,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 1024,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 60\n",
    "    batch_size = 10\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertLSTMCNNTransformerModel\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    #processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa8844-ffc8-4860-b555-52e357860a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Epoch 1/60:   0%|          | 0/87 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   1%|          | 1/87 [00:03<05:06,  3.56s/it, train_loss=1.0101]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   2%|▏         | 2/87 [00:05<03:26,  2.42s/it, train_loss=1.0236]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   3%|▎         | 3/87 [00:06<02:52,  2.06s/it, train_loss=1.0235]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   5%|▍         | 4/87 [00:08<02:42,  1.95s/it, train_loss=1.0186]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   6%|▌         | 5/87 [00:10<02:33,  1.88s/it, train_loss=1.0244]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   7%|▋         | 6/87 [00:11<02:24,  1.79s/it, train_loss=1.0170]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   8%|▊         | 7/87 [00:13<02:18,  1.73s/it, train_loss=1.0124]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   9%|▉         | 8/87 [00:15<02:15,  1.72s/it, train_loss=1.0165]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  10%|█         | 9/87 [00:16<02:11,  1.69s/it, train_loss=1.0110]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  11%|█▏        | 10/87 [00:18<02:12,  1.72s/it, train_loss=1.0121]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  13%|█▎        | 11/87 [00:20<02:08,  1.69s/it, train_loss=1.0134]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  14%|█▍        | 12/87 [00:22<02:08,  1.71s/it, train_loss=1.0055]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  15%|█▍        | 13/87 [00:23<02:08,  1.74s/it, train_loss=1.0101]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  16%|█▌        | 14/87 [00:25<02:04,  1.70s/it, train_loss=1.0112]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  17%|█▋        | 15/87 [00:27<02:03,  1.71s/it, train_loss=1.0154]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  18%|█▊        | 16/87 [00:28<02:02,  1.72s/it, train_loss=1.0123]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  20%|█▉        | 17/87 [00:30<01:58,  1.69s/it, train_loss=1.0146]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  21%|██        | 18/87 [00:32<01:54,  1.66s/it, train_loss=1.0162]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  22%|██▏       | 19/87 [00:33<01:53,  1.67s/it, train_loss=1.0190]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  23%|██▎       | 20/87 [00:35<01:53,  1.69s/it, train_loss=1.0236]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  24%|██▍       | 21/87 [00:37<01:46,  1.61s/it, train_loss=1.0244]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  25%|██▌       | 22/87 [00:38<01:43,  1.59s/it, train_loss=1.0233]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  26%|██▋       | 23/87 [00:40<01:42,  1.60s/it, train_loss=1.0170]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  28%|██▊       | 24/87 [00:41<01:42,  1.62s/it, train_loss=1.0158]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  29%|██▊       | 25/87 [00:43<01:38,  1.59s/it, train_loss=1.0081]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  30%|██▉       | 26/87 [00:45<01:38,  1.61s/it, train_loss=1.0053]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  31%|███       | 27/87 [00:46<01:37,  1.63s/it, train_loss=1.0021]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  32%|███▏      | 28/87 [00:48<01:38,  1.67s/it, train_loss=1.0011]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  33%|███▎      | 29/87 [00:49<01:31,  1.57s/it, train_loss=1.0008]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  34%|███▍      | 30/87 [00:51<01:32,  1.62s/it, train_loss=1.0009]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  36%|███▌      | 31/87 [00:53<01:31,  1.64s/it, train_loss=0.9993]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  37%|███▋      | 32/87 [00:54<01:30,  1.65s/it, train_loss=0.9994]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  38%|███▊      | 33/87 [00:56<01:30,  1.68s/it, train_loss=0.9980]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  39%|███▉      | 34/87 [00:58<01:27,  1.64s/it, train_loss=0.9978]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  40%|████      | 35/87 [00:59<01:25,  1.65s/it, train_loss=1.0004]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  41%|████▏     | 36/87 [01:01<01:24,  1.66s/it, train_loss=0.9985]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  43%|████▎     | 37/87 [01:03<01:23,  1.66s/it, train_loss=0.9998]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  44%|████▎     | 38/87 [01:04<01:17,  1.57s/it, train_loss=1.0030]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  45%|████▍     | 39/87 [01:06<01:15,  1.57s/it, train_loss=1.0041]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1499, 1024])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([1499, 10, 3072])\n",
      "torch.Size([10, 1499, 3072])\n",
      "torch.Size([10, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:  46%|████▌     | 40/87 [01:07<01:17,  1.64s/it, train_loss=1.0038]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ll60k\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "            \"RespBertCNNModelV2\": {\n",
    "            'model' : RespBertCNNModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"output_size\": None  \n",
    "        },\n",
    "            \"RespBertLSTMModelV2\": {\n",
    "            'model': RespBertLSTMModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 3,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "            ,\n",
    "            \"RespBertLSTMCNNTransformerModel\": {\n",
    "            'model': RespBertLSTMCNNTransformerModel,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 1024,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 60\n",
    "    batch_size = 10\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertLSTMCNNTransformerModel\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    #processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5afacd4-e655-472e-b096-4b8b067df5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "(864, 480000)\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Epoch 1/60:   0%|          | 0/58 [00:00<?, ?it/s]/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/60:   0%|          | 0/58 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacity of 93.12 GiB of which 590.75 MiB is free. Including non-PyTorch memory, this process has 92.54 GiB memory in use. Of the allocated memory 90.94 GiB is allocated by PyTorch, and 954.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:355\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39m## same wav2vec2 base model and pipeline used in the paper\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39m#processor = AutoProcessor.from_pretrained(config[\"model_name\"])\u001b[39;00m\n\u001b[1;32m    353\u001b[0m processor \u001b[39m=\u001b[39m Wav2Vec2FeatureExtractor\u001b[39m.\u001b[39mfrom_pretrained(config[\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 355\u001b[0m train(\n\u001b[1;32m    356\u001b[0m     path_to_data\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/wav/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    357\u001b[0m     path_to_labels\u001b[39m=\u001b[39;49mpath\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mComParE2020_Breathing/lab/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    358\u001b[0m     window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    359\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    360\u001b[0m     config \u001b[39m=\u001b[39;49m config,\n\u001b[1;32m    361\u001b[0m     step_size\u001b[39m=\u001b[39;49mstep_size,\n\u001b[1;32m    362\u001b[0m     data_parts\u001b[39m=\u001b[39;49m data_parts ,\n\u001b[1;32m    363\u001b[0m     early_stopping_patience\u001b[39m=\u001b[39;49m early_stopping_patience,\n\u001b[1;32m    364\u001b[0m     epochs\u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    365\u001b[0m     processor \u001b[39m=\u001b[39;49m processor\n\u001b[1;32m    366\u001b[0m )\n",
      "File \u001b[1;32m/home/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_train_SOTA.py:146\u001b[0m\n\u001b[1;32m    144\u001b[0m input_values \u001b[39m=\u001b[39m batch_d\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    145\u001b[0m batch_lbs \u001b[39m=\u001b[39m batch_lbs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 146\u001b[0m outputs \u001b[39m=\u001b[39m model(input_values)\n\u001b[1;32m    147\u001b[0m loss \u001b[39m=\u001b[39m correlation_coefficient_loss(outputs, batch_lbs)\n\u001b[1;32m    148\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/home3/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_models.py:787\u001b[0m, in \u001b[0;36mRespBertLSTMCNNTransformerModel.forward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_values):\n\u001b[0;32m--> 787\u001b[0m     wav \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwav_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minput_values)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    788\u001b[0m     cnn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcnn(wav\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m    789\u001b[0m     lstm_output, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(wav)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:1228\u001b[0m, in \u001b[0;36mWavLMModel.forward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1223\u001b[0m hidden_states, extract_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_projection(extract_features)\n\u001b[1;32m   1224\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mask_hidden_states(\n\u001b[1;32m   1225\u001b[0m     hidden_states, mask_time_indices\u001b[39m=\u001b[39mmask_time_indices, attention_mask\u001b[39m=\u001b[39mattention_mask\n\u001b[1;32m   1226\u001b[0m )\n\u001b[0;32m-> 1228\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1229\u001b[0m     hidden_states,\n\u001b[1;32m   1230\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1231\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1232\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1233\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1234\u001b[0m )\n\u001b[1;32m   1236\u001b[0m hidden_states \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madapter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:808\u001b[0m, in \u001b[0;36mWavLMEncoderStableLayerNorm.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    800\u001b[0m         layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    801\u001b[0m             layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    802\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    805\u001b[0m             output_attentions,\n\u001b[1;32m    806\u001b[0m         )\n\u001b[1;32m    807\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 808\u001b[0m         layer_outputs \u001b[39m=\u001b[39m layer(\n\u001b[1;32m    809\u001b[0m             hidden_states,\n\u001b[1;32m    810\u001b[0m             attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    811\u001b[0m             output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    812\u001b[0m             position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    813\u001b[0m         )\n\u001b[1;32m    814\u001b[0m     hidden_states, position_bias \u001b[39m=\u001b[39m layer_outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    816\u001b[0m \u001b[39mif\u001b[39;00m skip_the_layer:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:651\u001b[0m, in \u001b[0;36mWavLMEncoderLayerStableLayerNorm.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, output_attentions)\u001b[0m\n\u001b[1;32m    649\u001b[0m attn_residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m    650\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 651\u001b[0m hidden_states, attn_weights, position_bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    652\u001b[0m     hidden_states,\n\u001b[1;32m    653\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    654\u001b[0m     position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    655\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    656\u001b[0m )\n\u001b[1;32m    657\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    658\u001b[0m hidden_states \u001b[39m=\u001b[39m attn_residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:474\u001b[0m, in \u001b[0;36mWavLMAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, output_attentions, index)\u001b[0m\n\u001b[1;32m    471\u001b[0m gated_position_bias \u001b[39m=\u001b[39m gate_output\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m position_bias\n\u001b[1;32m    472\u001b[0m gated_position_bias \u001b[39m=\u001b[39m gated_position_bias\u001b[39m.\u001b[39mview((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, tgt_len, tgt_len))\n\u001b[0;32m--> 474\u001b[0m attn_output, attn_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtorch_multi_head_self_attention(\n\u001b[1;32m    475\u001b[0m     hidden_states, attention_mask, gated_position_bias, output_attentions\n\u001b[1;32m    476\u001b[0m )\n\u001b[1;32m    478\u001b[0m \u001b[39mreturn\u001b[39;00m attn_output, attn_weights, position_bias\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/transformers/models/wavlm/modeling_wavlm.py:498\u001b[0m, in \u001b[0;36mWavLMAttention.torch_multi_head_self_attention\u001b[0;34m(self, hidden_states, attention_mask, gated_position_bias, output_attentions)\u001b[0m\n\u001b[1;32m    494\u001b[0m add_zero_attn \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[39m# PyTorch 1.3.0 has F.multi_head_attention_forward defined\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[39m# so no problem with backwards compatibility\u001b[39;00m\n\u001b[0;32m--> 498\u001b[0m attn_output, attn_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m    499\u001b[0m     query,\n\u001b[1;32m    500\u001b[0m     key,\n\u001b[1;32m    501\u001b[0m     value,\n\u001b[1;32m    502\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim,\n\u001b[1;32m    503\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m    504\u001b[0m     torch\u001b[39m.\u001b[39;49mempty([\u001b[39m0\u001b[39;49m]),\n\u001b[1;32m    505\u001b[0m     torch\u001b[39m.\u001b[39;49mcat((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_proj\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk_proj\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_proj\u001b[39m.\u001b[39;49mbias)),\n\u001b[1;32m    506\u001b[0m     bias_k,\n\u001b[1;32m    507\u001b[0m     bias_v,\n\u001b[1;32m    508\u001b[0m     add_zero_attn,\n\u001b[1;32m    509\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout,\n\u001b[1;32m    510\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    511\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    512\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m    513\u001b[0m     key_padding_mask,\n\u001b[1;32m    514\u001b[0m     output_attentions,\n\u001b[1;32m    515\u001b[0m     gated_position_bias,\n\u001b[1;32m    516\u001b[0m     use_separate_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    517\u001b[0m     q_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    518\u001b[0m     k_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    519\u001b[0m     v_proj_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    520\u001b[0m )\n\u001b[1;32m    522\u001b[0m \u001b[39m# [Seq_Len, Batch Size, ...] -> [Batch Size, Seq_Len, ...]\u001b[39;00m\n\u001b[1;32m    523\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5560\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5557\u001b[0m k \u001b[39m=\u001b[39m k\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m   5558\u001b[0m v \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 5560\u001b[0m attn_output \u001b[39m=\u001b[39m scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n\u001b[1;32m   5561\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m   5563\u001b[0m attn_output \u001b[39m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacity of 93.12 GiB of which 590.75 MiB is free. Including non-PyTorch memory, this process has 92.54 GiB memory in use. Of the allocated memory 90.94 GiB is allocated by PyTorch, and 954.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs_SOTA\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, data_parts=4, epochs=100, batch_size=10, early_stopping_patience=20, config = None, processor = None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    # Create CSV file for storing fold indices\n",
    "    fold_indices_df = pd.DataFrame(columns=['Fold', 'Train_Indices', 'Val_Indices'])\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=data_parts)\n",
    "    fold_metrics = []\n",
    "    # To accumulate metrics across folds for each epoch\n",
    "    train_acc_epoch = []\n",
    "    val_acc_epoch = []\n",
    "    test_acc_epoch = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir,config[\"model_name\"]))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(prepared_data)):\n",
    "        print(f\"Fold {fold + 1}/{data_parts}\")\n",
    "        best_model_path = f\"{run_dir}/best_model_fold{fold+1}\"\n",
    "        # Save fold indices\n",
    "        fold_indices_df = fold_indices_df._append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Indices': train_index.tolist(),\n",
    "            'Val_Indices': val_index.tolist()\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Split data\n",
    "        train_d, val_d = prepared_data[train_index], prepared_data[val_index]\n",
    "        train_lbs, val_lbs = prepared_labels[train_index], prepared_labels[val_index]\n",
    "        train_timesteps, val_timesteps = prepared_labels_timesteps[train_index], prepared_labels_timesteps[val_index]\n",
    "        \n",
    "        # Reshape data\n",
    "        train_d, train_lbs = reshaping_data_for_model(train_d, train_lbs)\n",
    "        val_d, val_lbs = reshaping_data_for_model(val_d, val_lbs)\n",
    "        test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "        \n",
    "        print(train_d.shape)\n",
    "\n",
    "        # Create datasets\n",
    "        #train_dataset = BreathingDataset(train_d, train_lbs, processor, window_size, step_sequence, augment=True)\n",
    "        train_dataset = BreathingDataset(train_d, train_lbs, processor,window_size, step_sequence)\n",
    "        val_dataset = BreathingDataset(val_d, val_lbs, processor, window_size, step_sequence)\n",
    "        test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers=2, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, collate_fn=val_dataset.collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, collate_fn=test_dataset.collate_fn)\n",
    "        print(config[\"output_size\"])\n",
    "        # Create and initialize model\n",
    "        model = config[\"model\"](config).to(device)\n",
    "        \n",
    "        #### training optimiser parameters fror apple\n",
    "        #learning_rate = 0.005 \n",
    "        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #### training optimiser parameters fror harma_2023 VRB model \n",
    "        learning_rate = 0.01 # From the paper\n",
    "        optimizer = optim.Adam(model.parameters())       \n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_loss_flat = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        # To accumulate metrics across folds for each epoch\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch_d, batch_lbs in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Combined validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_pred = []\n",
    "            with torch.no_grad():\n",
    "                for batch_d, batch_lbs in val_loader:\n",
    "                    input_values = batch_d.to(device)\n",
    "                    batch_lbs = batch_lbs.to(device)\n",
    "                    \n",
    "                    outputs = model(input_values)\n",
    "                    loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                    val_loss += loss.item()\n",
    "                    val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_pred = np.array(val_pred).reshape(val_timesteps.shape)\n",
    "            val_ground_truth = _get_ground_truth_labels([all_dict[i] for i in val_index], all_labels)\n",
    "            val_pred_flat = unsplit_data_ogsize(val_pred, window_size, step_sequence, 25, val_ground_truth.shape[-1])\n",
    "            val_prc_coef = _calculate_flattened_accuracy(val_pred_flat, val_ground_truth)\n",
    "            \n",
    "            # Accumulate metrics for this fold and epoch\n",
    "            train_acc.append(1- train_loss)\n",
    "            val_acc.append(1- val_loss)\n",
    "\n",
    "            # Log metrics\n",
    "            writer.add_scalar(f\"Loss/train_fold_{fold + 1}\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"Loss/val_fold_{fold + 1}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Pearson/val_fold_{fold + 1}\", val_prc_coef, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Pearson: {val_prc_coef:.4f}\")\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving best model...\")\n",
    "                best_val_loss = val_loss\n",
    "                best_val_loss_flat = val_prc_coef\n",
    "                early_stopping_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve for {early_stopping_counter} epochs.\")\n",
    "                #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "                # Load the best model's weights\n",
    "                model.load_state_dict(torch.load(best_model_path))\n",
    "                break\n",
    "\n",
    "        test_pred = []\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_d, batch_lbs in test_loader:\n",
    "                input_values = batch_d.to(device)\n",
    "                batch_lbs = batch_lbs.to(device)\n",
    "                \n",
    "                outputs = model(input_values)\n",
    "                loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "                test_loss += loss.item()\n",
    "                test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "        test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "        test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "        test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Validation Pearson Coefficient  acc: {1- best_val_loss}\")\n",
    "        print(f\"  Validation Pearson Coefficient flat acc: {best_val_loss_flat}\")\n",
    "        print(f\"  Test acc: {1- test_loss}\")\n",
    "        print(f\"  Test Pearson Coefficient acc(flattened): {test_prc_coef}\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'val_prc_acc': 1- best_val_loss,\n",
    "            'val_prc_acc_flat': best_val_loss_flat,\n",
    "            'test_acc': 1- test_loss,\n",
    "            'test_prc_flat': test_prc_coef\n",
    "        })\n",
    "\n",
    "\n",
    "                # Log fold-specific metrics as tables\n",
    "        fold_table = f\"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                     f\"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                     f\"| {fold + 1} | {1 - val_loss:.4f} | {val_prc_coef:.4f} | {1 - test_loss:.4f} | {test_prc_coef:.4f} |\\n\"\n",
    "        writer.add_text(f\"Fold_{fold + 1}_Metrics\", fold_table)\n",
    "        # Accumulate fold metrics across all folds\n",
    "        train_acc_epoch.append(train_acc)\n",
    "        val_acc_epoch.append(train_acc)\n",
    "\n",
    "\n",
    "    \n",
    "        # After all folds, compute and log the average metrics per epoch across all folds\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = np.mean([fold_losses[epoch] for fold_losses in train_acc_epoch if len(fold_losses) > epoch])\n",
    "        avg_val_loss = np.mean([fold_losses[epoch] for fold_losses in val_acc_epoch if len(fold_losses) > epoch])\n",
    "\n",
    "        # Log the averaged metrics for the epoch across all folds\n",
    "        writer.add_scalar(\"Average_acc/train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Average_acc/val\", avg_val_loss, epoch)\n",
    "            \n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics if key != 'Fold']) for key in fold_metrics[0].keys() if key != 'Fold'}\n",
    "        # Log the final average table\n",
    "    avg_table = \"| Fold | Val Pearson Acc | Val Pearson Flat | Test Acc | Test Pearson Flat |\\n\" \\\n",
    "                \"|------|-----------------|------------------|----------|-------------------|\\n\" \\\n",
    "                f\"| Average | {avg_metrics['val_prc_acc']:.4f} | {avg_metrics['val_prc_acc_flat']:.4f} | {avg_metrics['test_acc']:.4f} | {avg_metrics['test_prc_flat']:.4f} |\\n\"\n",
    "    writer.add_text(\"Average_Metrics\", avg_table)\n",
    "    # Add average metrics to results\n",
    "    avg_metrics['Fold'] = 'Average'\n",
    "    fold_metrics.append(avg_metrics)\n",
    "\n",
    "    # save averga date to CSV\n",
    "    results_df = pd.DataFrame(fold_metrics)\n",
    "    csv_path = os.path.join(run_dir, 'fold_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save fold indices CSV\n",
    "    fold_indices_df.to_csv(os.path.join(run_dir, 'fold_indices.csv'), index=False)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Average metrics across all folds:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    #path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ll60k\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "            \"RespBertCNNModelV2\": {\n",
    "            'model' : RespBertCNNModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"output_size\": None  \n",
    "        },\n",
    "            \"RespBertLSTMModelV2\": {\n",
    "            'model': RespBertLSTMModelV2,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 3,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "            ,\n",
    "            \"RespBertLSTMCNNTransformerModel\": {\n",
    "            'model': RespBertLSTMCNNTransformerModel,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 1024,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 60\n",
    "    batch_size = 15\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    data_parts = 4 # aka folds\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertLSTMCNNTransformerModel\"]\n",
    "    \n",
    "\n",
    "    ## same wav2vec2 base model and pipeline used in the paper\n",
    "    #processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        data_parts= data_parts ,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        processor = processor\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
