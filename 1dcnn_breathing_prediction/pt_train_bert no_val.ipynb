{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1188, 480000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/70:   0%|          | 0/92 [00:00<?, ?it/s]/gpfs/home3/gdwildt/Master_thesis/1dcnn_breathing_prediction/pt_dataset.py:213: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/gdwildt/.conda/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 1/70: 100%|██████████| 92/92 [03:29<00:00,  2.28s/it, train_loss=0.9981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70 - Train Loss: 0.9981\n",
      "train loss improved from inf to 0.9981. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/70: 100%|██████████| 92/92 [03:26<00:00,  2.24s/it, train_loss=0.9028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/70 - Train Loss: 0.9028\n",
      "train loss improved from 0.9981 to 0.9028. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/70: 100%|██████████| 92/92 [03:26<00:00,  2.24s/it, train_loss=0.4762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/70 - Train Loss: 0.4762\n",
      "train loss improved from 0.9028 to 0.4762. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/70: 100%|██████████| 92/92 [03:27<00:00,  2.26s/it, train_loss=0.3678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/70 - Train Loss: 0.3678\n",
      "train loss improved from 0.4762 to 0.3678. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/70: 100%|██████████| 92/92 [03:28<00:00,  2.26s/it, train_loss=0.3345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/70 - Train Loss: 0.3345\n",
      "train loss improved from 0.3678 to 0.3345. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/70: 100%|██████████| 92/92 [03:26<00:00,  2.25s/it, train_loss=0.3121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/70 - Train Loss: 0.3121\n",
      "train loss improved from 0.3345 to 0.3121. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/70: 100%|██████████| 92/92 [03:22<00:00,  2.20s/it, train_loss=0.2898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/70 - Train Loss: 0.2898\n",
      "train loss improved from 0.3121 to 0.2898. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/70: 100%|██████████| 92/92 [03:27<00:00,  2.26s/it, train_loss=0.2736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/70 - Train Loss: 0.2736\n",
      "train loss improved from 0.2898 to 0.2736. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/70: 100%|██████████| 92/92 [03:24<00:00,  2.22s/it, train_loss=0.2608]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/70 - Train Loss: 0.2608\n",
      "train loss improved from 0.2736 to 0.2608. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/70: 100%|██████████| 92/92 [03:26<00:00,  2.24s/it, train_loss=0.2249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/70 - Train Loss: 0.2249\n",
      "train loss improved from 0.2608 to 0.2249. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/70: 100%|██████████| 92/92 [03:25<00:00,  2.24s/it, train_loss=0.2138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/70 - Train Loss: 0.2138\n",
      "train loss improved from 0.2249 to 0.2138. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/70: 100%|██████████| 92/92 [03:27<00:00,  2.25s/it, train_loss=0.2251]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/70 - Train Loss: 0.2251\n",
      "train loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/70: 100%|██████████| 92/92 [03:27<00:00,  2.25s/it, train_loss=0.2113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/70 - Train Loss: 0.2113\n",
      "train loss improved from 0.2138 to 0.2113. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/70: 100%|██████████| 92/92 [03:24<00:00,  2.23s/it, train_loss=0.2107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/70 - Train Loss: 0.2107\n",
      "train loss improved from 0.2113 to 0.2107. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/70: 100%|██████████| 92/92 [03:25<00:00,  2.23s/it, train_loss=0.1969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/70 - Train Loss: 0.1969\n",
      "train loss improved from 0.2107 to 0.1969. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/70: 100%|██████████| 92/92 [03:22<00:00,  2.20s/it, train_loss=0.2042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/70 - Train Loss: 0.2042\n",
      "train loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/70: 100%|██████████| 92/92 [03:26<00:00,  2.24s/it, train_loss=0.1979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/70 - Train Loss: 0.1979\n",
      "train loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/70: 100%|██████████| 92/92 [03:22<00:00,  2.20s/it, train_loss=0.1951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/70 - Train Loss: 0.1951\n",
      "train loss improved from 0.1969 to 0.1951. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/70: 100%|██████████| 92/92 [03:26<00:00,  2.25s/it, train_loss=0.1765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/70 - Train Loss: 0.1765\n",
      "train loss improved from 0.1951 to 0.1765. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/70: 100%|██████████| 92/92 [02:58<00:00,  1.94s/it, train_loss=0.1887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/70 - Train Loss: 0.1887\n",
      "train loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/70: 100%|██████████| 92/92 [02:58<00:00,  1.94s/it, train_loss=0.1709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/70 - Train Loss: 0.1709\n",
      "train loss improved from 0.1765 to 0.1709. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/70: 100%|██████████| 92/92 [02:58<00:00,  1.94s/it, train_loss=0.1834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/70 - Train Loss: 0.1834\n",
      "train loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/70: 100%|██████████| 92/92 [02:59<00:00,  1.95s/it, train_loss=0.1781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/70 - Train Loss: 0.1781\n",
      "train loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/70: 100%|██████████| 92/92 [03:01<00:00,  1.97s/it, train_loss=0.1648]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/70 - Train Loss: 0.1648\n",
      "train loss improved from 0.1709 to 0.1648. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/70: 100%|██████████| 92/92 [02:59<00:00,  1.95s/it, train_loss=0.1659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/70 - Train Loss: 0.1659\n",
      "train loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/70: 100%|██████████| 92/92 [02:56<00:00,  1.91s/it, train_loss=0.1686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/70 - Train Loss: 0.1686\n",
      "train loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/70: 100%|██████████| 92/92 [02:58<00:00,  1.94s/it, train_loss=0.1646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/70 - Train Loss: 0.1646\n",
      "train loss improved from 0.1648 to 0.1646. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/70: 100%|██████████| 92/92 [02:57<00:00,  1.93s/it, train_loss=0.1594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/70 - Train Loss: 0.1594\n",
      "train loss improved from 0.1646 to 0.1594. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/70: 100%|██████████| 92/92 [02:58<00:00,  1.93s/it, train_loss=0.1638]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/70 - Train Loss: 0.1638\n",
      "train loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/70: 100%|██████████| 92/92 [02:57<00:00,  1.93s/it, train_loss=0.1430]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/70 - Train Loss: 0.1430\n",
      "train loss improved from 0.1594 to 0.1430. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/70: 100%|██████████| 92/92 [02:59<00:00,  1.95s/it, train_loss=0.1537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/70 - Train Loss: 0.1537\n",
      "train loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/70: 100%|██████████| 92/92 [02:58<00:00,  1.94s/it, train_loss=0.1753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/70 - Train Loss: 0.1753\n",
      "train loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/70: 100%|██████████| 92/92 [02:58<00:00,  1.94s/it, train_loss=0.1453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/70 - Train Loss: 0.1453\n",
      "train loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/70: 100%|██████████| 92/92 [02:58<00:00,  1.94s/it, train_loss=0.1747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/70 - Train Loss: 0.1747\n",
      "train loss did not improve for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/70: 100%|██████████| 92/92 [02:58<00:00,  1.94s/it, train_loss=0.1661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/70 - Train Loss: 0.1661\n",
      "train loss did not improve for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/70: 100%|██████████| 92/92 [03:00<00:00,  1.97s/it, train_loss=0.1623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/70 - Train Loss: 0.1623\n",
      "train loss did not improve for 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/70: 100%|██████████| 92/92 [03:00<00:00,  1.97s/it, train_loss=0.1527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/70 - Train Loss: 0.1527\n",
      "train loss did not improve for 7 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/70: 100%|██████████| 92/92 [02:58<00:00,  1.94s/it, train_loss=0.1626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/70 - Train Loss: 0.1626\n",
      "train loss did not improve for 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/70: 100%|██████████| 92/92 [02:59<00:00,  1.95s/it, train_loss=0.1391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/70 - Train Loss: 0.1391\n",
      "train loss improved from 0.1430 to 0.1391. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/70: 100%|██████████| 92/92 [03:00<00:00,  1.96s/it, train_loss=0.1406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/70 - Train Loss: 0.1406\n",
      "train loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/70: 100%|██████████| 92/92 [03:10<00:00,  2.07s/it, train_loss=0.1489]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/70 - Train Loss: 0.1489\n",
      "train loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/70: 100%|██████████| 92/92 [03:17<00:00,  2.15s/it, train_loss=0.1324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/70 - Train Loss: 0.1324\n",
      "train loss improved from 0.1391 to 0.1324. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/70: 100%|██████████| 92/92 [03:25<00:00,  2.23s/it, train_loss=0.1347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/70 - Train Loss: 0.1347\n",
      "train loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/70: 100%|██████████| 92/92 [03:27<00:00,  2.26s/it, train_loss=0.1478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/70 - Train Loss: 0.1478\n",
      "train loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/70: 100%|██████████| 92/92 [03:25<00:00,  2.24s/it, train_loss=0.1481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/70 - Train Loss: 0.1481\n",
      "train loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/70: 100%|██████████| 92/92 [03:26<00:00,  2.25s/it, train_loss=0.1359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/70 - Train Loss: 0.1359\n",
      "train loss did not improve for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/70: 100%|██████████| 92/92 [03:26<00:00,  2.24s/it, train_loss=0.1392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/70 - Train Loss: 0.1392\n",
      "train loss did not improve for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/70: 100%|██████████| 92/92 [03:26<00:00,  2.25s/it, train_loss=0.1270]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/70 - Train Loss: 0.1270\n",
      "train loss improved from 0.1324 to 0.1270. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/70: 100%|██████████| 92/92 [03:27<00:00,  2.25s/it, train_loss=0.1474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/70 - Train Loss: 0.1474\n",
      "train loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/70: 100%|██████████| 92/92 [03:25<00:00,  2.24s/it, train_loss=0.1475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/70 - Train Loss: 0.1475\n",
      "train loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/70: 100%|██████████| 92/92 [03:22<00:00,  2.20s/it, train_loss=0.1197]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/70 - Train Loss: 0.1197\n",
      "train loss improved from 0.1270 to 0.1197. Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/70: 100%|██████████| 92/92 [03:21<00:00,  2.19s/it, train_loss=0.1316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/70 - Train Loss: 0.1316\n",
      "train loss did not improve for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/70: 100%|██████████| 92/92 [03:26<00:00,  2.24s/it, train_loss=0.1292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/70 - Train Loss: 0.1292\n",
      "train loss did not improve for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/70: 100%|██████████| 92/92 [03:27<00:00,  2.26s/it, train_loss=0.1226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/70 - Train Loss: 0.1226\n",
      "train loss did not improve for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/70: 100%|██████████| 92/92 [03:26<00:00,  2.24s/it, train_loss=0.1395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/70 - Train Loss: 0.1395\n",
      "train loss did not improve for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/70: 100%|██████████| 92/92 [03:25<00:00,  2.24s/it, train_loss=0.1284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/70 - Train Loss: 0.1284\n",
      "train loss did not improve for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/70: 100%|██████████| 92/92 [03:28<00:00,  2.26s/it, train_loss=0.1247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/70 - Train Loss: 0.1247\n",
      "train loss did not improve for 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/70: 100%|██████████| 92/92 [03:26<00:00,  2.25s/it, train_loss=0.1386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/70 - Train Loss: 0.1386\n",
      "train loss did not improve for 7 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/70: 100%|██████████| 92/92 [03:26<00:00,  2.24s/it, train_loss=0.1312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/70 - Train Loss: 0.1312\n",
      "train loss did not improve for 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/70: 100%|██████████| 92/92 [03:28<00:00,  2.27s/it, train_loss=0.1337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/70 - Train Loss: 0.1337\n",
      "train loss did not improve for 9 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/70: 100%|██████████| 92/92 [03:23<00:00,  2.21s/it, train_loss=0.1204]\n",
      "/scratch-local/gdwildt.8231237/ipykernel_2583639/2696157896.py:152: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/70 - Train Loss: 0.1204\n",
      "train loss did not improve for 10 epochs.\n",
      "Early stopping triggered at epoch 61. Loading best model.\n",
      "\n",
      "Training completed.\n",
      "Final Test Loss: 0.1734\n",
      "Final Test Pearson Coefficient (flattened): 0.8159\n",
      "Results saved to pt_runs/20241021-145824/final_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
    "import torchaudio\n",
    "from typing import List, Tuple\n",
    "from pt_utils import *\n",
    "from pt_dataset import *\n",
    "from pt_models import *\n",
    "from pt_utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def create_run_directory():\n",
    "    base_dir = \"pt_runs\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def _calculate_flattened_accuracy(average, ground_truth_labels):\n",
    "    s_acc = 0\n",
    "    for b in range(len(ground_truth_labels)):\n",
    "        s, _ = scipy.stats.pearsonr(average[b], ground_truth_labels[b])\n",
    "        s_acc += s\n",
    "    return s_acc / len(ground_truth_labels)\n",
    "\n",
    "def _choose_real_labs_only_with_filenames(labels, filenames):\n",
    "    return labels[labels['filename'].isin(filenames)]\n",
    "\n",
    "def _get_ground_truth_labels(ground_truth_names, labels):\n",
    "    ground_truth_labels = []\n",
    "    for batch_name in ground_truth_names:\n",
    "        ground_truth_label = _choose_real_labs_only_with_filenames(labels, [batch_name])\n",
    "        ground_truth_labels.append(ground_truth_label)\n",
    "    return np.array(ground_truth_labels)[:, :, -1].astype(np.float32)\n",
    "\n",
    "def train(path_to_data, path_to_labels, window_size=16, step_size=6, early_stopping_patience=10,epochs=100, batch_size=10, config=None, model=None, processor=None):\n",
    "    run_dir = create_run_directory()\n",
    "    log_dir = os.path.join(run_dir, \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Parameters\n",
    "    length_sequence = window_size \n",
    "    step_sequence = step_size\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_data, train_labels, train_dict, frame_rate = load_data(path_to_data, path_to_labels, 'train')\n",
    "    devel_data, devel_labels, devel_dict, frame_rate = load_data(path_to_data, path_to_labels, 'devel')\n",
    "    test_data, test_labels, test_dict, frame_rate = load_data(path_to_data, path_to_labels, 'test')\n",
    "\n",
    "    # Combine train and devel data\n",
    "    all_data = np.concatenate((train_data, devel_data), axis=0)\n",
    "    all_labels = pd.concat([train_labels, devel_labels])\n",
    "    all_dict = np.concatenate((list(train_dict.values()), list(devel_dict.values())), axis=0)\n",
    "\n",
    "    # Prepare data\n",
    "    prepared_data, prepared_labels, prepared_labels_timesteps = prepare_data(all_data, all_labels, all_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "    prepared_test_data, prepared_test_labels, prepared_test_labels_timesteps = prepare_data(test_data, test_labels, test_dict, frame_rate, length_sequence * 16000, step_sequence * 16000)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    config[\"output_size\"] = prepared_labels.shape[-1]\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir, config[\"model_name\"]))\n",
    "\n",
    "    # Reshape data\n",
    "    train_d, train_lbs = reshaping_data_for_model(prepared_data, prepared_labels)\n",
    "    test_d, test_lbs = reshaping_data_for_model(prepared_test_data, prepared_test_labels)\n",
    "    \n",
    "    print(train_d.shape)\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = GPUBreathingDataset(train_d, train_lbs, processor, augment=True)\n",
    "    test_dataset = BreathingDataset(test_d, test_lbs, processor, window_size, step_sequence)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=5, collate_fn=test_dataset.collate_fn)\n",
    "\n",
    "    # Create and initialize model\n",
    "    model = config[\"model\"](config).to(device)\n",
    "\n",
    "    # Optimizer and scheduler setup\n",
    "    learning_rate = 5e-4\n",
    "    weight_decay = 0.001\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    total_steps = len(train_loader) * epochs\n",
    "    warmup_steps = int(total_steps * 0.1)\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
    "                                         num_warmup_steps=warmup_steps, \n",
    "                                         num_training_steps=total_steps)\n",
    "\n",
    "    best_train_loss = float('inf')\n",
    "    best_model_path = f\"{run_dir}/best_model\"\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for input_values, batch_lbs in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(input_values)\n",
    "            loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            progress_bar.set_postfix({'train_loss': f'{train_loss/(progress_bar.n+1):.4f}'})\n",
    "            scheduler.step()\n",
    "                        # Clear cache\n",
    "            del input_values, batch_lbs, outputs, loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Log metrics\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "        if train_loss < best_train_loss:\n",
    "            print(f\"train loss improved from {best_train_loss:.4f} to {train_loss:.4f}. Saving best model...\")\n",
    "            best_train_loss = train_loss\n",
    "            early_stopping_counter = 0\n",
    "\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            print(f\"train loss did not improve for {early_stopping_counter} epochs.\")\n",
    "            #model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "        # Early stopping\n",
    "        if early_stopping_counter >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}. Loading best model.\")\n",
    "            # Load the best model's weights\n",
    "            #model.load_state_dict(torch.load(best_model_path))\n",
    "            break\n",
    "\n",
    "    # Load the best model for final evaluation\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    # Evaluate model on test data\n",
    "    model.eval()\n",
    "    test_pred = []\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_d, batch_lbs in test_loader:\n",
    "            input_values = batch_d.to(device)\n",
    "            batch_lbs = batch_lbs.to(device)\n",
    "            \n",
    "            outputs = model(input_values)\n",
    "            loss = correlation_coefficient_loss(outputs, batch_lbs)\n",
    "            test_loss += loss.item()\n",
    "            test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_pred = np.array(test_pred).reshape(prepared_test_labels_timesteps.shape)\n",
    "    test_ground_truth = _get_ground_truth_labels(list(test_dict.values()), test_labels)\n",
    "    test_pred_flat = unsplit_data_ogsize(test_pred, window_size, step_sequence, 25, test_ground_truth.shape[-1])\n",
    "    test_prc_coef = _calculate_flattened_accuracy(test_pred_flat, test_ground_truth)\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(f\"Final Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Final Test Pearson Coefficient (flattened): {test_prc_coef:.4f}\")\n",
    "\n",
    "    # Log final test metrics\n",
    "    writer.add_scalar(\"Final/test_loss\", test_loss, 0)\n",
    "    writer.add_scalar(\"Final/test_pearson_coef\", test_prc_coef, 0)\n",
    "\n",
    "    # Log the final test metrics as a table\n",
    "    final_table = \"| Metric | Value |\\n\" \\\n",
    "                  \"|--------|-------|\\n\" \\\n",
    "                  f\"| Test Loss | {test_loss:.4f} |\\n\" \\\n",
    "                  f\"| Test Pearson Coefficient | {test_prc_coef:.4f} |\\n\"\n",
    "    writer.add_text(\"Final_Test_Metrics\", final_table)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    # Save final results to CSV\n",
    "    results_df = pd.DataFrame({\n",
    "        'Test_Loss': [test_loss],\n",
    "        'Test_Pearson_Coefficient': [test_prc_coef]\n",
    "    })\n",
    "    csv_path = os.path.join(run_dir, 'final_results.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"Results saved to {csv_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Path to data\n",
    "    path = \"/home/glenn/Downloads/\"\n",
    "    path = \"../DATA/\"\n",
    "\n",
    "\n",
    "    # Model parameters\n",
    "    model_config = {\n",
    "        \"VRBModel\": {\n",
    "            \"model\" : VRBModel,\n",
    "            \"model_name\": \"facebook/hubert-large-ls960-ft\",\n",
    "            \"hidden_units\": 64,\n",
    "            \"n_gru\": 3,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"Wav2Vec2ConvLSTMModel\": {\n",
    "            \"model\" : Wav2Vec2ConvLSTMModel,\n",
    "            \"model_name\": \"facebook/wav2vec2-base\",\n",
    "            \"hidden_units\": 128,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  # Will be set dynamically\n",
    "        },\n",
    "        \"RespBertLSTMModel\": {\n",
    "            'model': RespBertLSTMModel,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 256,\n",
    "            \"n_lstm\": 2,\n",
    "            \"output_size\": None  \n",
    "        },\n",
    "        \"RespBertAttionModel\": {\n",
    "            'model' : RespBertAttionModel,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 512,\n",
    "            \"n_attion\": 2,\n",
    "            \"output_size\": None  \n",
    "        },\n",
    "            \"RespBertCNNModel\": {\n",
    "            'model' : RespBertCNNModel,\n",
    "            \"model_name\": \"microsoft/wavlm-large\",\n",
    "            \"hidden_units\": 256,\n",
    "            \"output_size\": None  \n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and data parameters\n",
    "    epochs = 70\n",
    "    batch_size = 13\n",
    "    window_size = 30\n",
    "    step_size = 6\n",
    "    early_stopping_patience = 10\n",
    "    \n",
    "    config = model_config[\"RespBertCNNModel\"]\n",
    "    #model\n",
    "    \n",
    "    model = None\n",
    "\n",
    "    #processor = AutoProcessor.from_pretrained(config[\"model_name\"])\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(config[\"model_name\"])\n",
    "\n",
    "\n",
    "    train(\n",
    "        path_to_data=path+\"ComParE2020_Breathing/wav/\",\n",
    "        path_to_labels=path+\"ComParE2020_Breathing/lab/\",\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        config = config,\n",
    "        step_size=step_size,\n",
    "        early_stopping_patience= early_stopping_patience,\n",
    "        epochs= epochs,\n",
    "        model= model,\n",
    "        processor = processor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
